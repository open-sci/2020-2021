{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Science Project Diary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Getting to Know the Research Questions (25/03/2021)](#entry_1)\n",
    "2. [Writing the Abstract (30/03/2021)](#entry_2)\n",
    "3. [Creating the Project Management Plan (01/04/2021 -- 07/04/2021)](#entry_3)\n",
    "4. [Creating Jupyter Notebooks and Revising the DMP (10/04/2021)](#entry_4)\n",
    "5. [Bibliographic Research (11/04/2021 -- 13/04/2021)](#entry_5)\n",
    "6. [Crossref API Service querying and collegial discussion on further data management (11/04/2021 -- 13/04/2021)](#entry_6)\n",
    "7. [Preliminary studies on publications about protocols (11/04/2021 -- 13/04/2021)](#entry_7)\n",
    "8. [Protocol creation (13/04/2021)](#entry_8)\n",
    "9. [DMP review (16/04/2021 -- 20/04/2021)](#entry_9)\n",
    "10. [Collective Discussion about Licenses to be adopted (21/04/2021)](#entry_10)\n",
    "11. [Protocol Reviews Analysis (23/04/2021)](#entry_11)\n",
    "12. [Flow Diagram Creation and Protocol Update (24/04/2021 -- 26/04/2021)](#entry_12)\n",
    "13. [Rebuttal letter for reviews on the protocol (26/04/2021 -- 27/04/2021)](#entry_13)\n",
    "14. [DMP Reviews analysis, DMP update and Rebuttal Letter (26/04/2021 -- 28/04/2021)](#entry_14)\n",
    "15. [Starting to write the article of the project (29/04/2021)](#entry_15)\n",
    "16. [Finishing to write the article (30/04/2021)](#entry_16)\n",
    "17. [Setting up the visualisations (1/05/2021)](#entry_17)\n",
    "18. [Finishing the graphs and uploading them on the website (2/05/2021)](#entry_18)\n",
    "19. [Finishing the article and creation of material.md (3/05/2021)](#entry_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting to Know the Research Questions (25/03/2021) <a class=\"anchor\" id=\"entry_1\"></a>\n",
    "\n",
    "\n",
    "We studied the two offered research questions, and after discussing among ourselves in our WhatsApp group and with the other group, we chose to do the one about investigating the sources of the missing citations and the related publishers sending and receiving invalid citation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Abstract (30/03/2021) <a class=\"anchor\" id=\"entry_2\"></a>\n",
    "\n",
    "After reviewing the slides and getting to know the OpenCitations project a little more, and learning the correct way to write a project abstract from [the guide from Emerald publishing offered in the course slides](https://www.emeraldgrouppublishing.com/how-to/authoring-editing-reviewing/write-article-abstract), we commenced writing the abstract for our project, which can be found [here](https://github.com/open-sci/2020-2021/blob/master/docs/TheLeftovers20/abstract.md). It was a challenging step, because we had to think about our project consciously and meticulously before having started getting our hands dirty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Project Management Plan (01/04/2021 -- 07/04/2021) <a class=\"anchor\" id=\"entry_3\"></a>\n",
    "\n",
    "During and after the class of 01/04/2021 (some of us were not present during the final hour because of a previously set exam) we created ORCID IDs for the group members. Afterwards, in the days preceding the lesson of the 8th, we created the Data Management Plan using the [OpenAIRE Argos Website](http://argos.openaire.eu/). We wrote the main explanations of the project all together in a group video call, and divided ourselves into two groups for inserting the data for each dataset. Arianna and I put in the data for the dataset relating to the output data (titled _Missing Citations in COCI_). We all read some data on lesser-known fields to us such as licenses during the video call together.\n",
    "\n",
    "We then uploaded it to [Zenodo](https://zenodo.org/record/4671487) in PDF, JSON, and XML formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Jupyter Notebooks and Revising the DMP (10/04/2021) <a class=\"anchor\" id=\"entry_4\"></a>\n",
    "\n",
    "\n",
    "After the clarifications made in the 8 April class, we started our individual Jupyter Notebooks (almost identical up to this point since we did everything together, but not necessarily so in the future) in a diary format and also we updated the FAIR part of the DMP based on our new knowledge of the metadata solutions available in Zenodo. Now we have a [new version of the DMP](https://doi.org/10.5281/zenodo.4704464). We also divided in two groups to carry out two different tasks: the bibliographic research (me and Alessia) and the analysis of COCI software (Arianna and Nooshin) in order to have a complete overview on what to write in the protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographic Research (11/04/2021 -- 13/04/2021) <a class=\"anchor\" id=\"entry_5\"></a>\n",
    "\n",
    "To better understand the methodology we will have to implement and the steps to follow, me and Alessia looked for literature either about the same domain of COCI or regarding steps that we consider necessary to carry out the tasks of our project, even if applied to different domains.\n",
    "\n",
    "Firstly, I tried to better analyze the research question and its sub-parts, in order to have a better idea on how we can answer it, identifying the possible proceeding so to find relevant papers.\n",
    "\n",
    "The selected resources can be divided in two main groups:\n",
    "\n",
    "1. BIBLIOGRAPHY ON OPENCITATIONS AND SIMILAR PROJECTS\n",
    " - Martín-Martín, A., Thelwall, M., Orduna-Malea, E. et al. Google Scholar, Microsoft Academic, Scopus, Dimensions, Web of Science, and OpenCitations’ COCI: a multidisciplinary comparison of coverage via citations. Scientometrics 126, 871–906 (2021). https://doi.org/10.1007/s11192-020-03690-4.\n",
    " - Garcia A, Lopez F, Garcia L, Giraldo O, Bucheli V, Dumontier M. 2018. Biotea: semantics for Pubmed Central. PeerJ 6:e4201 https://doi.org/10.7717/peerj.4201.\n",
    " - Bagnacani A., Ciancarini P., Di Iorio A., Nuzzolese A.G., Peroni S., Vitali F. (2015) The Semantic Lancet Project: A Linked Open Dataset for Scholarly Publishing. In: Lambrix P. et al. (eds) Knowledge Engineering and Knowledge Management. EKAW 2014. Lecture Notes in Computer Science, vol 8982. Springer, Cham. https://doi.org/10.1007/978-3-319-17966-7_10.\n",
    " - Alexiou G., Vahdati S., Lange C., Papastefanatos G., Lohmann S. (2016) OpenAIRE LOD Services: Scholarly Communication Data as Linked Data. In: González-Beltrán A., Osborne F., Peroni S. (eds) Semantics, Analytics, Visualization. Enhancing Scholarly Data. SAVE-SD 2016. Lecture Notes in Computer Science, vol 9792. Springer, Cham. https://doi.org/10.1007/978-3-319-53637-8_6.\n",
    " - Heibi, I., Peroni, S. & Shotton, D. Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations. Scientometrics 121, 1213–1228 (2019). https://doi.org/10.1007/s11192-019-03217-6.\n",
    "2. BIBLIOGRAPHY ON SIMILAR METHODOLOGY/WORKFLOW (BUT CAN HAVE DIFFERENT DOMAIN)\n",
    " - Zhu, J., Hu, G. & Liu, W. DOI errors and possible solutions for Web of Science. Scientometrics 118, 709–718 (2019). https://doi.org/10.1007/s11192-018-2980-7.\n",
    " - Boudry, C., Chartron, G. Availability of digital object identifiers in publications archived by PubMed. Scientometrics 110, 1453–1469 (2017). https://doi-org.ezproxy.unibo.it/10.1007/s11192-016-2225-6.\n",
    " - Fiorenzo Franceschini, Domenico Maisano, Luca Mastrogiacomo,\n",
    "Scientific journal publishers and omitted citations in bibliometric databases: Any relationship?, Journal of Informetrics, Volume 8, Issue 3, 2014, 751-765, ISSN 1751-1577, https://doi.org/10.1016/j.joi.2014.07.003.\n",
    " - Zhuoren Jiang and Xiaozhong Liu. 2013. Recovering missing citations in a scholarly network: a 2-step citation analysis to estimate publication importance. In Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries (JCDL '13). Association for Computing Machinery, New York, NY, USA, 419–420. DOI:https://doi.org/10.1145/2467696.2467782.\n",
    " - B. Ian Hutchins,Kirk L. Baker,Matthew T. Davis,Mario A. Diwersy,Ehsanul Haque,Robert M. Harriman,Travis A. Hoppe,Stephen A. Leicht,Payam Meyer,George M. Santangelo, The NIH Open Citation Collection: A public access, broad coverage resource, Plos Biology, 2019, https://doi.org/10.1371/journal.pbio.3000385.\n",
    " - Nishioka C. and Farber M., Evaluating the Availability of Open Citation\n",
    "Data, Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (2019), 2414: 123-129. http://hdl.handle.net/2433/244871.\n",
    " - PENTZ, Ed. CrossRef: The missing link. College & Research Libraries News, v. 62, n. 2, p. 206-228, feb. 2001. ISSN 2150-6698. Available at: https://crln.acrl.org/index.php/crlnews/article/view/22135/28119. doi: https://doi.org/10.5860/crln.62.2.206."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossref API Service querying and collegial discussion on further data management (11/04/2021 -- 13/04/2021) <a class=\"anchor\" id=\"entry_6\"></a>\n",
    "\n",
    "Meanwhile, we also started querying Crossref API service with some sample DOIs, so to be able to make some considerations about the amount and the quality of data we are going to extract information from. During this step, we realised that the two alternative ways we worked out to retrieve information about publisher given a DOI seem to be in contrast. In particular, we noticed that - starting from a same DOI - the publisher that could be traced back to from the firs six characters of the identifier was not the same retrievable from the response of the Crossref API request. For this reason, we decided to ask for clarifications before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary studies on publications about protocols (11/04/2021 -- 13/04/2021) <a class=\"anchor\" id=\"entry_7\"></a>\n",
    "\n",
    "Before scratching our own protocol, we studied an exemplar protocol proposed at lesson (A methodology for gathering and annotating the raw-data/characteristics of the documents citing a retracted article V.1). In addition, we selected and analysed some further publications, both on protocols structuring in general and on our specific research topics in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol creation (13/04/2021) <a class=\"anchor\" id=\"entry_8\"></a>\n",
    "\n",
    "At this point, we concretely structured the protocol for our workflow. For a matter of computational order, we preferred to address first the third research question (i.e. the one related to the previously invalid DOIs which can nowadays be re-labelled as valid). In relation to this point, we discussed how to manage the invalid_dois.csv file after this step, and whether the citations with now valid cited DOIs were supposed to be included in the further steps of the research, where we plan to identify publishers of both citing and cited DOIs. In order to find an optimal balance between computational cost and preservation of information that could be potentially useful for further analysis based on data we are handling, we decided to discuss this aspect with the course Professor Silvio Peroni before proceeding.\n",
    "In the end, we decided to structure the protocol ([Investigating Invalid DOIs in COCI](https://www.protocols.io/view/investigating-invalid-dois-in-coci-bt5xnq7n)) in the following listed points:\n",
    "1.  \tReading CSV data\n",
    "2.  \tCreation of the output JSON file\n",
    "3.     Processing of each CSV file line and extraction of required information and differentiation of the further management of still invalid and now valid DOIs.\n",
    "4.  \tExtraction of data about publishers for both citing and cited articles from their DOIs and management of the case in which the first 6 characters are not a valid ID\n",
    "5.  \tReturn of the completed JSON file after processing all the lines\n",
    "Further, we contemplate the idea to add a further CSV file to store the retrieved information, to enable additional research on the produced material.\n",
    "For this week we kept working mostly collegially, since we agreed that everyone of us should have a broad comprehension of all the aspects of the workflow before splitting it more markedly in the next phases. However,  I especially worked on the preliminary phase of selection of relevant publications to create a well-documented protocol, and then I also focused on its effective implementation with Nooshin, in light of collegial consideration about the way in which the workflow steps could be divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DMP review (16/04/2021 -- 20/04/2021) <a class=\"anchor\" id=\"entry_9\"></a>\n",
    "\n",
    "Having to produce a review of the Data Management Plan carried out by Grasshoppers group on their research, I have read some relevant papers to better understand how to carry out and structure a review, and especially a review for this kind of publication. Selected resources are:\n",
    "1. Economic and Social Research Council, UKRI. (2019). Data management plan: Guidance for peer reviewers. https://esrc.ukri.org/files/about-us/policies-and-standards/data-management-plan-guidance-for-per-reviewers/\n",
    "2. Ross-Hellauer, T. (2017). What is open peer review? A systematic review. F1000Research, 6, 588. https://doi.org/10.12688/f1000research.11369.2\n",
    "3. The guidelines to assist reviewers in reviewing such scholarly resources provided by the International Semantic Web Conference series: https://iswc2021.semanticweb.org/resources-track.\n",
    "\n",
    "While the first one is specifically thought for producing appropriate reviews of Data Management Plans, the second one has been a useful resource to have a better understanding of what is an open peer review in the Open Science environment; and useful were also the several reviews provided with the article itself, which allowed me to have an idea about all the possible structures a review can have. The last one helped me to retrieve relevant topics to take into account in a review of a scholarly resource in general, regardless of the type of the resource itself.\n",
    "\n",
    "Finally, after writing the review, the final quality check of the review was carried out by using this resource as main guidelines: Reviewer’s rights and duties. (2019). https://open-sci.github.io/review/.\n",
    "The final review is available in Qeios: https://doi.org/10.32388/3V7ITH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collective Discussion about Licenses to be adopted (21/04/2021) <a class=\"anchor\" id=\"entry_10\"></a>\n",
    "\n",
    "With the occasion of the discussion born in the Github issue called \"[Choosing the software license for the main repository](https://github.com/open-sci/2020-2021/issues/11)\", I inquired about the main licenses currently used in this academic context in order to actively participate in the discussion. I browsed the same website where I've found the information necessary to choose a license for the code of our group, the Leftovers 2.0, which are: https://opensource.org/licenses, https://www.gnu.org/licenses/license-list.en.html.\n",
    "Since it was suggested to us to choose a license that maximises the software reuse (i.e. with limited constraints), I focused on ISC (which is the license proposed by professor Peroni) and MIT because I think they are very clear, straightforward and the most suitable for the whole project purposes. I agree with my collegues Nooshin and Cristian when stating that \"the mere compatibility of other, shorter licenses (such as MIT and ISC) to the GPLv3 can be a clear enough pointer to their being reliable free software licenses\" and \"I personally prefer licenses that just ensure authorship attribution without putting too much restrictions on further distribution\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol Reviews Analysis (23/04/2021) <a class=\"anchor\" id=\"entry_11\"></a>\n",
    "\n",
    "My group mates and I collectively read and analysed the reviews of our protocol (Review of: Investigating Invalid DOIs in COCI by Deniz Tural and Review of: Investigating Invalid DOIs in COCI by Arcangelo Massari). We tried to understand the received critics and suggestions, and then we discussed some possible ways to improve the quality of our original protocol. In order to formalise our opinion about our colleagues’ advice, we separately answered both reviews point by point, and then we tried to summarise the answers to the repeated suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Diagram Creation and Protocol Update (24/04/2021 -- 26/04/2021) <a class=\"anchor\" id=\"entry_12\"></a>\n",
    "In accordance with the content of the material collected during the reviews’ analysis, we decided to refine both our protocol and – consequently – the steps planned for our software development. In order to define the passages in a detailed and unequivocal way, we created a flow diagram in draw.io, where we explained step-by-step the process from the input to the output material.\n",
    "In the creation of the diagram, we realised the necessity to make some further research about the mechanism to retrieve the publishers’ identifiers. At the end of this phase, we confirmed our decision of opting for a Crossref request, exploiting this base url: https://api.crossref.org/prefixes/  + the first six digits of the doi of the publication of which we are trying to identify the publisher (e.g.: 10.1161).\n",
    "This response is particularly useful for our purposes, since it provides both information about the publisher’s name and a confirmation of the validity of its code, i.e.: the identifier composed by the first six digits of the doi of the publication.\n",
    "We also discussed the possibility of providing different kinds of outputs, depending on the purpose of output data (a JSON file to answer the research questions and one or two CSV files for the visualizations of our findings). \n",
    "\n",
    "Once the diagram was completed, we planned and realised the next update of our protocol. However, we all agreed it could not be the final version of the protocol itself, since we are planning to perfectionate it after the finalization of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuttal letter for reviews on the protocol (26/04/2021 -- 27/04/2021) <a class=\"anchor\" id=\"entry_13\"></a>\n",
    "\n",
    "While updating the protocol or right after making the changes, we wrote the answers for the comments in the reviews on our protocol, in order to produce and publish the rebuttal letter. We explained how we addressed the issues brought to light or provided a robust justification in the cases in which we decided to reject the suggestions. We revised together all the answers, and the possibility to improve or increase the number of changes made to the protocol.\n",
    "\n",
    "The updated version of the protocol was published at: https://dx.doi.org/10.17504/protocols.io.buhjnt4n.\n",
    "\n",
    "Finally, the rebuttal letter was published on Zenodo: http://doi.org/10.5281/zenodo.4725899."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMP Reviews analysis, DMP update and Rebuttal Letter (26/04/2021 -- 28/04/2021) <a class=\"anchor\" id=\"entry_14\"></a>\n",
    "\n",
    "In the same days when we discussed and modified the protocol according to the suggestions presented by our colleagues Arcangelo and Deniz in their reviews, we also revised our DMP with the very same method: collective discussion about possible changing or improvements; updating the Data Management Plan; and answering the comments, questions and suggestions made by Cristian Santini ([review by Cristian](https://doi.org/10.32388/DIA06O)) and Ricarda Boente ([review by Ricarda](https://doi.org/10.32388/T0UF3H)). This time we were much more aware of our project, and thus we updated the DMP more carefully and with more details.\n",
    "\n",
    "The updated version of the DMP was published at: https://doi.org/10.5281/zenodo.4726095.\n",
    "\n",
    "Those answers were then formally merged into one rebuttal letter, then published in Zenodo: https://doi.org/10.5281/zenodo.4725729."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Starting to write the article of the project (29/04/2021) <a class=\"anchor\" id=\"entry_15\"></a>\n",
    "## Study of what a scientific article is: preparing for our article\n",
    "Today Alessia and I have started to write down the article about our research. In a first moment we had a meeting to decide how to structure the articles, the sections in which it should be divided, the materials necessary to be shown and its style and length. About this part we created a Google drive shared file on which we have <b>appointed the suggestions given by the professor during the lecture, the instructions of the bibliographic material and some other articles which dealt with that topic</b>. We decided to create 5 sections: introduction, materials and methods, results, discussion and conclusions. For each of the sections we tried to understand the contents to talk about and the suggested length.\n",
    "\n",
    "## Sharing the work in writing the article\n",
    "To optimize time and so that each of us would write about the part she was most informed about and knew best, me and Alessia decided to split the first two chapters (<b>introduction and materials and methods</b>), half to each, and to conclude them by the following day. From a practical perspective, we thought it was better to assign the writing of the results and discussion section to Arianna and Nooshin, which are taking care of writing the code. In this way we can complete the first 2 parts while they are developing the code; then, while they will write their parts we will start to work on the website, where the results will be shown, and the visualizations that will represent the selected output data. After talking with our colleagues, they agreed to proceed in this way.\n",
    "That day, after the collective discussion, Alessia and I finished the first chapter, the introduction. In particular I dealt with the introduction of the <b>research questions, purpose of the research and objectives of our work</b>.\n",
    "\n",
    "## Bibliography\n",
    "Borja A. 11 steps to structuring a science paper editors will take seriously - Elsevier Connect\n",
    "Kallestinova E. D. (2011). How to write your first research paper. The Yale journal of biology and medicine, 84(3), 181–190."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finishing to write the article (30/04/2021)<a class=\"anchor\" id=\"entry_16\"></a>\n",
    "Today, as prevented yesterday, me and Alessia had to finish our part of the article, the <b>materials and methods section</b>. In this case we split the job so that I should have written about the materials directly connected to the software like the input and output materials, while Alessia has written about the subject of study and of the materials indirectly regarding the software like the protocol and the DMP. In the morning we also had a call with Arianna in order to understand the structure they had given to the code, which is helpful both for understanding the software itself and to write the article. As planned, <b>the code was written according to the flow diagram we all worked on</b>, structuring the algorithm on which the code is now based on. By the end of the day, the methods and materials part was ready."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up the visualisations (1/05/2021)<a class=\"anchor\" id=\"entry_17\"></a>\n",
    "Since me and Alessia have finished our part of the article, we finally have started to work on the website and on its visualisations. In the morning we had a call in order to put up the website. We started from scratch using bootstrap and we created a <b>one-page website with five main sections</b>: introduction, one section of each of the three main research questions (their explanations and graphical representations of the results), the conclusion, and an \"about\" section. In the afternoon instead we took some decisions regarding the <b>visualization tools and the type of visualizations</b> we intended to use in order to graphically show the results of the research:\n",
    " - for the first and second question, since they ask similar results from a datatype point of view, we chose a table in which we will show all the publisher responsible for invalid cited DOIs; and a stacked bar chart, which allows to see the proportion between the total number of originary invalid citations and the numbers of the now valid/still invalid citations.\n",
    " - for the third question a pie chart which shows the percentage of now valid citations on the original total number of invalid citations.\n",
    "\n",
    "Today we focused on the table and the bar chart: we extracted relevant data from the sample output json file, and structured it in the appropriate data structure for the visualizations. Tomorrow we will finish with the pie chart and adjust all the visualizations and data explanation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finishing the graphs and uploading them on the website (2/05/2021)<a class=\"anchor\" id=\"entry_18\"></a>\n",
    "Today me and Alessia have finished the graphs. As organized the day before we produced two graphical representations of the data for the first and the second questions and one for the third. For the first two we created a <b>table</b> for each, which represents the direct answer to the questions, i.e., the publishers of the correct citing DOIs and to which publishers did the invalid DOIs point to. Then we created a <b>stacked barchart</b> for each of the first two questions in order to show the 20 most cited and citing publishers. Through a stacked chart indeed we are able to show at the same time the total number of citations for each publisher, the total number of now valid citations and the number of still invalid citations. Since the third question was structurally different from the others, we decided to use a different graphical representation in order to show the results: a <b>donut chart</b>. Indeed, it is able to show the percentage of the total number of now validated graphs with respect to the total number of previously invalid citations. Also in the center of the chart it is shown the real number of citations which actually answers the question (How many invalid citations has now become valid?).\n",
    "Finally we uploaded the script code and html paragraphs of the graphics, and the js libraries required to realize the graphics (<b>chart.js and d3.js</b>)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finishing the article and creation of material.md (3/05/2021)<a class=\"anchor\" id=\"entry_19\"></a>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}