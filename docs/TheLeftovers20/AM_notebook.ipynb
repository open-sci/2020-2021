{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Science Project Diary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Getting to Know the Research Questions (25/03/2021)](#entry_1)\n",
    "2. [Writing the Abstract (30/03/2021)](#entry_2)\n",
    "3. [Creating the Project Management Plan (01/04/2021 - 07/04/2021)](#entry_3)\n",
    "4. [Creating Jupyter Notebooks and Revising the DMP (10/04/2021)](#entry_4)\n",
    "5. [Open Citations infrastructure preliminary study (11/04/2021 - 14/04/2021)](#entry_5)\n",
    "6. [Crossref API Service Querying and Collective Discussion on Further Data Management (11/04/2021 - 14/04/2021)](#entry_6)\n",
    "7. [Preliminary Studies for the Publication of our Protocol (11/04/2021 - 14/04/2021)](#entry_7)\n",
    "8. [Structuring The Protocol (12/04/2021 - 14/04/2021)](#entry_8)\n",
    "9. [Writing a Review of a Protocol (15/04/2021 - 21/04/2021)](#entry_9)\n",
    "10. [Collective Discussion about Licenses to be adopted (21/04/2021)](#entry_10)\n",
    "11. [Protocol Reviews Analysis (23/04/2021 - 28/04/2021)](#entry_11)\n",
    "12. [Flow Diagram Creation and Protocol Update (23/04/2021 - 28/04/2021)](#entry_12)\n",
    "13. [Data Management Plan Update (23/04/2021 - 28/04/2021)](#entry_13)\n",
    "14. [Reviews’ Answers (23/04/2021 - 28/04/2021)](#entry_14)\n",
    "15. [Code projecting and discussion about the output(28/04/2021 - 29/04/2021)](#entry_15)\n",
    "16. [Work on the Presentation (28/04/2021 - 04/05/2021)](#entry_16)\n",
    "17. [Flow Diagrams Finalization and Protocol Update (29/04/2021 - 03/05/2021)](#entry_17)\n",
    "18. [Code Refactoring (30/04/2021 - 01/05/2021)](#entry_18)\n",
    "19. [Article Writing and Finalization of the Project(30/04/2021-03/05/2021)](#entry_19)\n",
    "20. [Group Discussion on Received Comments (10/05/2021)](#entry_20)\n",
    "21. [Validation Time Management (Code) (25/05/2021)](#entry_21)\n",
    "22. [Unit Testing (Code) (31/05/2021)](#entry_22)\n",
    "23. [Input/output files generalization and tests update (Code) (1/06/2021)](#entry_23)\n",
    "24. [Prefix Matching Improvement and Switch to Crossref Member Codes as Publishers' Keys in publisher_data dictionary (Code) (10/06/2021-12/06/2021)](#entry_24)\n",
    "25. [Final Dataset Upload (23/06/2021)](#entry_25)\n",
    "26. [Protocol Update and Last Version Release (03/07/2021 - 05/07/2021)](#entry_26)\n",
    "27. [Last Meeting, Article Update and Last Version Publication (03/07/2021 - 05/07/2021)](#entry_27)\n",
    "28. [Issue Closure (06/07/2021)](#entry_28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting to Know the Research Questions (25/03/2021) <a class=\"anchor\" id=\"entry_1\"></a>\n",
    "\n",
    "\n",
    "We studied the two offered research questions, and after discussing among ourselves in our WhatsApp group and with the other group, we chose to do the one about investigating the sources of the missing citations and the related publishers sending and receiving invalid citation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Abstract (30/03/2021) <a class=\"anchor\" id=\"entry_2\"></a>\n",
    "\n",
    "After reviewing the slides and getting to know the OpenCitations project a little more, and learning the correct way to write a project abstract from [the guide from Emerald publishing offered in the course slides](https://www.emeraldgrouppublishing.com/how-to/authoring-editing-reviewing/write-article-abstract), we commenced writing the abstract for our project, which can be found [here](https://github.com/open-sci/2020-2021/blob/master/docs/TheLeftovers20/abstract.md). It was a challenging step, because we had to think about our project consciously and meticulously before having started getting our hands dirty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Project Management Plan (01/04/2021 -- 07/04/2021) <a class=\"anchor\" id=\"entry_3\"></a>\n",
    "\n",
    "During and after the class of 01/04/2021 (some of us were not present during the final hour because of a previously set exam) we created ORCID IDs for the group members. Afterwards, in the days preceding the lesson of the 8th, we created the Data Management Plan using the [OpenAIRE Argos Website](http://argos.openaire.eu/). We wrote the main explanations of the project all together in a group video call, and divided ourselves into two groups for inserting the data for each dataset. Sara and I put in the data for the dataset relating to the output data (titled _Missing Citations in COCI_). We all read some data on lesser-known fields to us such as licenses during the video call together.\n",
    "\n",
    "We then uploaded it to [Zenodo](https://zenodo.org/record/4671487) in PDF, JSON, and XML formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Jupyter Notebooks and Revising the DMP (10/04/2021) <a class=\"anchor\" id=\"entry_4\"></a>\n",
    "\n",
    "After the clarifications made in the 8 April class, we started our individual Jupyter Notebooks (almost identical up to this point since we did everything together, but not necessarily so in the future) in a diary format and also we updated the FAIR part of the DMP based on our new knowledge of the metadata solutions available in Zenodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Citations infrastructure preliminary study (11/04/2021 - 14/04/2021) <a class=\"anchor\" id=\"entry_5\"></a>\n",
    "Before proceeding with the creation of a protocol for our project, we analysed accurately the structure of OpenCitations software, so to make sure to have properly understood the way in which data from Crossref are managed in COCI at code level.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossref API Service Querying and Collective Discussion on Further Data Management (11/04/2021 - 14/04/2021) <a class=\"anchor\" id=\"entry_6\"></a>\n",
    "Meanwhile, we also started querying Crossref API service with some sample DOIs, so to be able to make some considerations about the amount and the quality of the data we are going to extract information from. During this step, we realised that the two alternative ways we worked out to retrieve information about publisher given a DOI seem to be in contrast. In particular, we noticed that - starting from a same DOI - the publisher that could be traced back to from the firs six characters of the identifier was not the same retrievable from the response of the Crossref API request. For this reason, we decided to ask for clarifications before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Studies for the Publication of our Protocol (11/04/2021 - 14/04/2021) <a class=\"anchor\" id=\"entry_7\"></a>\n",
    "Before scratching our own protocol, we studied an exemplar protocol proposed at lesson (<a href= https://www.protocols.io/view/a-methodology-for-gathering-and-annotating-the-raw-bdc4i2yw.html> A methodology for gathering and annotating the raw-data/characteristics of the documents citing a retracted article V.1 </a>). In addition, we selected and analysed some further publications, both on protocols structuring in general and on our specific research topics in particular.\n",
    "<ul>\n",
    "    <li><a href=\"https://link.springer.com/article/10.1007/s11192-020-03690-4\">Google Scholar, Microsoft Academic, Scopus, Dimensions, Web of Science, and OpenCitations’ COCI: a multidisciplinary comparison of coverage via citations</a></li>\n",
    "    <li><a href=\"https://link.springer.com/article/10.1007/s11192-019-03217-6\">Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations</a></li>\n",
    "    <li><a href=\"https://peerj.com/articles/4201/\">Biotea: semantics for Pubmed Central</a></li>\n",
    "    <li><a href=\"https://link-springer-com.ezproxy.unibo.it/content/pdf/10.1007/s11192-018-2980-7.pdf\">DOI errors and possible solutions for Web of Science</a></li>\n",
    "    <li><a href=\"https://www-sciencedirect-com.ezproxy.unibo.it/science/article/pii/S1751157714000637\">Scientific journal publishers and omitted citations in bibliometric databases: Any relationship?</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring The Protocol (12/04/2021 - 14/04/2021) <a class=\"anchor\" id=\"entry_8\"></a>\n",
    "At this point, we concretely structured the protocol for our workflow. For a matter of computational order, we preferred to address first the third research question (i.e. the one related to the previously invalid DOIs which can nowadays be re-labelled as valid). In relation to this point, we discussed how to manage the invalid_dois.csv file after this step, and whether the citations with now valid cited DOIs were supposed to be included in the further steps of the research, where we plan to identify publishers of both citing and cited DOIs. In order to find an optimal balance between computational cost and preservation of information that could be potentially useful for further analysis based on data we are handling, we decided to discuss this aspect with the course Professor Silvio Peroni before proceeding.\n",
    "\n",
    "For this week we kept working mostly collegially, since we agreed that everyone of us should have a broad comprehension of all the aspects of the workflow before splitting it more markedly in the next phases. However, after OpenCitations code analysis and some general tests on Crossref API service, Alessia and I mainly focused on the revision of the way we planned to implement research questions in light of some considerations arisen during our group meetings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Review of a Protocol (15/04/2021 - 21/04/2021) <a class=\"anchor\" id=\"entry_9\"></a>\n",
    "\n",
    "# References:\n",
    "<li>Ricarda Boente, Deniz Tural, Cristian Santini, Arcangelo Massari 2021. Investigating DOIs' classes of errors. protocols.io, https://dx.doi.org/10.17504/protocols.io.bt65nrg6, Version created by Arcangelo Massari </li>\n",
    "<li>Ivan Heibi, Silvio Peroni 2020. A methodology for gathering and annotating the raw-data/characteristics of the documents citing a retracted article. protocols.io https://dx.doi.org/10.17504/protocols.io.bdc4i2yw</li>\n",
    "<li>Ross-Hellauer, T. (2017). What is open peer review? A systematic review. F1000Research, 6, 588. https://doi.org/10.12688/f1000research.11369.2 </li>\n",
    "\n",
    "<li>https://direct.mit.edu/qss/pages/submission-guidelines</li>\n",
    "<li>https://iswc2021.semanticweb.org/resources-track </li>\n",
    "<li>https://github.com/open-sci/2020-2021</li>\n",
    "<li>https://journals.plos.org/ </li>\n",
    "<li>http://www.semantic-web-journal.net/reviewers</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collective Discussion About Licenses to Be Adopted (21/04/2021) <a class=\"anchor\" id=\"entry_10\"></a>\n",
    "I studied advantages and disadvantages of each license and then selected the most suitable two, according to my knowledge and personal opinion. \n",
    "\n",
    "Then, I gave my opinion commenting the <a href =\"https://github.com/open-sci/2020-2021/issues/11\">GitHub issue Choosing the software license for the main repository </a> as follow: \n",
    "\n",
    "As my colleagues proposed, I'd suggest to choose a license which is as clear and concise as possible, while staying permissive too. Since ISC and MIT are very close for their purposes and their differences don't seem to be so relevant in their factual application, I'd personally choose ISC because it is expressed with unequivocal language and therefore it can be understood by anyone, also with none or a very limited knowledge of the undelying legal background.\n",
    "However, MIT license makes explicit mention of sublicensing too, while ISC doesn't. Further, the slightly more complex structure of MIT could - to some extent - also facilitate the resolution of some doubts that could araise in particular circumstances.\n",
    "For these reasons, even if I personally prefer ISC license, I totally agree to adopt also MIT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol Reviews Analysis (23/04/2021 - 28/04/2021)  <a class=\"anchor\" id=\"entry_11\"></a>\n",
    "\n",
    "My group mates and I collectively read and analysed the reviews of our protocol by Deniz Tural and Arcangelo Massari (<a href=\"https://doi.org/10.32388/WHWOI8\">Review of: Investigating Invalid DOIs in COCI v1 by Deniz Tural</a> , <a href=\"https://doi.org/10.32388/X2DX81\">Review of: Investigating Invalid DOIs in COCI v1 by Arcangelo Massari</a>) . We tried to understand the received critics and suggestions, and then we discussed some possible ways to improve the quality of our original protocol.\n",
    "In order to formalise our opinion about our colleagues’ advice, we separately answered both reviews point by point, and then we tried to summarise the answers to the repeated suggestions.\n",
    "\n",
    "### References:\n",
    "1) Deniz Tural. (2021). Review of: \"Investigating Invalid DOIs in COCI v1 (protocols.io.bt5xnq7n)\". Qeios. doi:10.32388/WHWOI8.\n",
    "2) Arcangelo Massari. (2021). Review of: \"Investigating Invalid DOIs in COCI\". Qeios. doi:10.32388/X2DX81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Diagram Creation and Protocol Update (23/04/2021 - 28/04/2021)  <a class=\"anchor\" id=\"entry_12\"></a>\n",
    "\n",
    "In accordance with the content of the material collected during the reviews’ analysis, we decided to refine both our protocol and – consequently – the steps planned for our software development. In order to define the passages in a detailed and unequivocal way, we created a flow diagram in draw.io, where we explained step-by-step the process from the input to the output material.\n",
    "In the creation of the diagram, we realised the necessity to make some further research about the mechanism to retrieve the publishers’ identifiers. At the end of this phase, we confirmed our decision of opting for a Crossref request, exploiting this base url : <a href =\"https://api.crossref.org/prefixes/\"> https://api.crossref.org/prefixes/</a>  + the first six digits of the doi of the publication of which we are trying to identify the publisher (e.g.: 10.1161).  \n",
    "\n",
    "Example:\n",
    "{\"status\":\"ok\",\"message-type\":\"prefix\",\"message-version\":\"1.0.0\",\"message\":{\"member\":\"http:\\/\\/id.crossref.org\\/member\\/276\",\"name\":\"Ovid Technologies (Wolters Kluwer Health)\",\"prefix\":\"http:\\/\\/id.crossref.org\\/prefix\\/10.1161\"}}\n",
    "\n",
    "This response is particularly useful for our purposes, since it provides both information about the publisher’s name and a confirmation of the validity of its code, i.e.: the identifier composed by the first six digits of the doi of the publication.\n",
    "Once the diagram was completed, we planned and realised the next update of our protocol. However, we all agreed it could not be the final version of the protocol itself, since we are planning to improve it after the finalization of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management Plan Update (23/04/2021 - 28/04/2021) <a class=\"anchor\" id=\"entry_13\"></a>\n",
    "Separately, we started the same process (i.e.: reviews’ analysis, discussion, and answer, together with our material’s correction and update) for what concerns the DMP.\n",
    "\n",
    "Also in this case, we collectively analysed the received reviews (i.e.: <a href=\"https://doi.org/10.32388/DIA06O\"> Review of: Investigating Missing Citations in COCI (1.0) by Cristian Santini </a>, <a href=\"https://doi.org/10.32388/T0UF3H\"> Review of: DMP Investigating Missing Citations in COCI (zenodo.4671487) by Ricarda Boente</a>) and tried to take decisions which could represent a balance between the proposed suggestions and the will of all the Leftovers 2.0 members. \n",
    "\n",
    "### References\n",
    "1) Cristian Santini. (2021). Review of: \"Investigating Missing Citations in COCI (1.0)\". Qeios. doi:10.32388/DIA06O.\n",
    "2) Ricarda Boente. (2021). Review of: \"DMP Investigating Missing Citations in COCI (zenodo.4671487)\". Qeios. doi:10.32388/T0UF3H.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews’ Answers (23/04/2021 - 28/04/2021)  <a class=\"anchor\" id=\"entry_14\"></a>\n",
    "With the material collected in the previous phases of our workflow, we answered the received reviews of our protocol, pointing out where we accepted the suggestions and where we had to reject them. In both cases, we tried to motivate our decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Project and Discussion About the Output(28/04/2021 - 29/04/2021)<a class=\"anchor\" id=\"entry_15\"></a>\n",
    "After the creation of the flow diagram and the update of our protocol, we started discussing about the code. First of all, we decided the information we wanted to store in the output and we chose a suitable format to present the results. In the end, we opted for a JSON output file, in order to exploit its highly structurability to organize our data in three main key-values pairs:\n",
    "1) \"publishers\", a list of dictionaries, each one representing a specific publisher by providing information about: its name, the number of validated citations it addressed, the number of invalid citations it addressed, the number of validated citations it received and the number of invalid citations it received.\n",
    "2) \"citations\", a dictionary containing two lists: \"valid\", storing as dictionaries the citational data validated during the process, and \"invalid\", storing as dictionaries the citational data that could not be validated during the process.\n",
    "3) \"total_num_of_valid_citations\", a numerical datum representing the number of citational data validated in the process. This integer should correspond to the length of the list \"valid\".\n",
    "A firts draft of the code was then developed on the base of the previously created diagram, representing the first version of the algorithm. \n",
    "After some analysis and attempts, we decided to manage the issue of the identification of the publishers by exploiting the Crossref API service for prefixes, from which the publishers of the Digital Object Identifiers are retieved. However, as we realized that more than one single prefix could be associated to the same publisher, we decided to address the issue by adding to each publisher's dictionary in \"publishers\" another key-value pair, storing the list of all the identifiers associated with the publisher in question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the Presentation (28/04/2021 - 04/05/2021)<a class=\"anchor\" id=\"entry_16\"></a>\n",
    "As soon as the major part of our project was realized, we started preparing a presentation on Canva. In particular, we decided to structure the presentation so to focus on: the environment in which we worked, the background of the project and the source of our data, the main aspects of the code's functioning and the structure of its output, the results we obtained and the derived visualizations, and in conclusion some talking points and the possible further developments of the project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Diagrams Finalization and Protocol Update (29/04/2021 - 03/05/2021)<a class=\"anchor\" id=\"entry_17\"></a>\n",
    "Once we had a clear idea of the final structure of the code, the flow diagram was corrected and updated, so that it could become a useful element to facilitate the comprehension of the code. A reduced version of the original one was also implemented, so to improve its readability. Then, accordingly, we updated the protocol with respect to the received suggestions and the further evolutions of our code. We enriched the previous version with immages, PDFs, and details on the procedure. The final version of the protocol and both the reduced and the complete version of the diagram are available <a href=\"https://dx.doi.org/10.17504/protocols.io.buqhnvt6\">here</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Refactoring (30/04/2021 - 01/05/2021)<a class=\"anchor\" id=\"entry_18\"></a>\n",
    "After having fixed some bugs in the original version of the code, we decided to divide it in several files, in order to provide a semantically coherent presentation of the ancillary functions. Further, we restructured some parts of the code deciding to compensate the removal of the global variables by passing the needed elements as arguments of the ancillary functions where they had to be manipulated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Writing and Finalization of the Project(30/04/2021-03/05/2021)<a class=\"anchor\" id=\"entry_19\"></a>\n",
    "We started working on the article by trying to assign to each of us the part she felt more comfortable with. \n",
    "In particular, Nooshin and I focused on the sections \"Discussion\", \"Results\", \"Conclusion\". Further, we described in detail in natural language the functions of our software, in the \"Materials and Methods\" section. \n",
    "After a collective discussion about some controversal aspects, we published the article on Zenodo.\n",
    "We also created the material.md file on the course and project repository, in which we specified the roles each of us carried out and cited all the resources produced since the beginning of the course.\n",
    "Finally, we published all the materials needed to present the whole research project on Wednesday: the article, the software, the last final version of the protocol and the output dataset.\n",
    "\n",
    "### References\n",
    "1) Borja A. 11 steps to structuring a science paper editors will take seriously - Elsevier Connect Kallestinova E. D. (2011). How to write your first research paper. The Yale journal of biology and medicine, 84(3), 181–190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Discussion on Received Comments (10/05/2021) <a class=\"anchor\" id=\"entry_20\"></a>\n",
    "After having individually analysed the comments received (see Issue <a href=\"https://github.com/open-sci/2020-2021/issues/31\">Revision of material - team The Leftovers 2.0 </a>), we had a meeting to discuss about how to address the suggested corrections so to improve our project, also in accordance with some interesting ideas came out during the workshop. \n",
    "Before implementing the final adjustments, we decided to ask for further clarifications about some points on which our comprehension was not univocal. \n",
    "Further, we welcomed Ivan Heibi idea of giving the user the possibility to decided how often the saving process to cache files should be set off: indeed, we are implementing this suggestion both in the protocol and in the code, so to improve reusability. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Time Management (Code) (25/05/2021) <a class=\"anchor\" id=\"entry_21\"></a>\n",
    "During the final workshop (05/05/2021) we received the suggestion of keeping track of the validity state of the citations by saving the time information related to the moment in which a given citation was declared either valid or invalid. \n",
    "Accordingly, today I worked on both invalid_dois.py and csv_writer.py files. In particular: \n",
    "<ol>\n",
    "    <li><b>invalid_dois.py</b>: I imported datetime and then I used datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\") to keep track of the time of validation. Then I added this latter piece of information to the row representing each citation. </li>\n",
    "    <li><b>csv_writer.py</b>: I added the header of the third column, so to manage the three element row obtained after the addition for each citation of the information related to the validation time (i.e.: writer.writerow(['Valid_citing_doi', 'Valid_cited_doi', \"Validation_time\"]))</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing (Code) (21/05/2021) <a class=\"anchor\" id=\"entry_22\"></a>\n",
    "With respect to what declared in Section 3.4.5 of <i>Missing Citations in COCI: Publishers Analytics Result</i> in our <a href=\"https://doi.org/10.5281/zenodo.4726095\">DMP</a>, we adopted documented procedure for quality assurance by developing unit tests for checking our software functioning on the overall and in its various components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/output files generalization and tests update (Code) (1/06/2021) <a class=\"anchor\" id=\"entry_23\"></a>\n",
    "We generalized the input and output file, so that the file paths can be specified by the user. In order to do that, the script in <a href=\"https://github.com/open-sci/2020-2021-the-leftovers-20-code/blob/main/invalid_dois.py\">invalid_dois.py</a> was englobed in a function (i.e.: invalid_dois_main), which takes as parameters the input and output files specified by the user. Similarly, the output file parameter was added also in <a href=\"https://github.com/open-sci/2020-2021-the-leftovers-20-code/blob/main/output_creator.py\">create_output function</a>. Further, another parameter was added, so to allow the user to specify the integer number of  rows after which the processed data are saved into the cache files.\n",
    "At this point, the origianl process could be reproduced by running  if __name__ == '__main__':\n",
    "    invalid_dois_main(100, \"invalid_dois.csv\", \"output.json\") in invalid_dois.py file.\n",
    "<br>\n",
    "Then we decided to further improve the reusability of the code by giving the user the possibility to run the software from the command line, without the necessity to directly interact with the code at all. Accordingly, my colleague Nooshin added a usage tutorial in the README.md file, which explicitly explains how to call the main function with the chosen parameters, which are supposed to be:\n",
    "<ol>\n",
    "    <li>An input CSV file with the same fields of the one used by us in the present study, but which could contain different citational data, have a different length, being a subset of the original one (e.g.: containing only the citational data which resulted invalid at a previous code run).</li>\n",
    "    <li>An output JSON file, where the final computed data will be stored. </li>\n",
    "    <li>A number of lines after which the processed information is stored in the cache file.</li>\n",
    "\n",
    "Letting the user choose this last parameter results significantly important, since the necessity to save the processed data more or less often is also related to the performance of the system on which the code is run. For the creation of our study output dataset we opted for storing the data to cache files each 100 lines, which was a good tradeoff solution with respect to our necessity and our system’s settings and characteristics. \n",
    "<br>\n",
    "Accordingly, <a href=\"https://github.com/open-sci/2020-2021-the-leftovers-20-code/blob/main/tests.py\">tests.py</a> was extended with another test function, testing the correct functioning of the new function invalid_dois_main(n, input_csv, output_json).\n",
    "A file named <a href=\"https://github.com/open-sci/2020-2021-the-leftovers-20-code/blob/main/ex_input.csv\">ex_input.csv</a> was created and uploaded, so to allow the execution of tests on a very small amount of data, having the same structure of the original input file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix Matching Improvement and Switch to Crossref Member Codes as Publishers' Keys in publisher_data dictionary (10/06/2021-12/06/2021)<a class=\"anchor\" id=\"entry_24\"></a>\n",
    "\n",
    "Welcoming the suggestions by our colleagues and by the experts invited to the Open Science Workshop (05/05/2021), we:\n",
    "<ol>\n",
    "    <li>switched to the unique codes assigned by Crossref to each publisher as unique keys in the publisher_dict dictionary, since these codes are more reliable than the strings of the publishers' names.</li>\n",
    "    <li>implemented a regex to match the doi prefixes for the rest API request, in order to increment the level of accuracy (in the previous version we just considered all the characters preceding the first \"/\" character as the doi prefix).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset Upload (23/06/2021)<a class=\"anchor\" id=\"entry_25\"></a>\n",
    "On the 20th the code run ended and produced the final version of our dataset, i.e.: <i>Missing Citations in COCI: Publishers Analytics Result</i>. The final version of the JSON output was then uploaded on Zenodo, with the doi <a href = \"http://doi.org/10.5281/zenodo.5018586\"> 10.5281/zenodo.5018586 </a>.\n",
    "The fields of the dictionary in which we stored our results are:\n",
    "<ol>\n",
    "    <li>\"publishers\", a list of dictionaries representing each publisher encountered;</li>\n",
    "    <li>\"citations\", a dictionary containing two lists, the one storing the validated citational data and the other storing the still invalid citational data. Each processed citation is represented as a dictionary. </li>\n",
    "    <li>\"total_num_of_valid_citations\", whose value is the number of citational data that could be validated throughout the process implemented by our software.</li>\n",
    "    <li>\"external_data_for_unrecognized_prefixes\": a dictionary of dictionaries representing the publishers we didn't find on Crossref, but that were identified through other online services. </li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol Update and Last Version Release (03/07/2021 - 05/07/2021)<a class=\"anchor\" id=\"entry_26\"></a>\n",
    "We corrected the format of the reference cited, as well as for the other references in the article. Further, given the limited formatting and layout options provided by the platform, we decided to visually differentiate code-related text by using bold characters (for example for variables, functions names…) and the italic for bibliographic references. \n",
    "We completed the final part of the protocol by showing a subsample dictionary which could be representative of the structure of our output materials. \n",
    "Finally, we updated the whole protocol with particular attention to change all the details that we updated in the software too. A very general image representing the main structure of our software was added, so to facilitate the visual comprehension of the related protocol as well. For the same purpose, we also added an updated pdf of the Flow Diagram.\n",
    "This last version of the protocol was then published and is now available <a href=\"http://dx.doi.org/10.17504/protocols.io.bv9jn94n\">here</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Meeting, Article Update and Last Version Publication (03/07/2021 - 05/07/2021)<a class=\"anchor\" id=\"entry_27\"></a> \n",
    "For what concerns the Subjects and Methods section, we welcomed the received suggestions and first of all we visually differentiated the text concerning the code by using Courier New font, in order to improve the visual quality of the article and to generally simplify the readers’ understanding of the explanations provided. \n",
    "Further, we restructured the whole software presentation by adopting a more divulgative and discursive explanatory approach. The code is not presented any more function by function, but its description is much more prone to present the various purposes which are addressed by the functions of each file in which the code is structured (i.e.: management of publishers’ identification, creation and compilation of the cache files, etc.). \n",
    "We also fostered the article comprehensibility by adding some visual support. In particular, we provided three images, representing:\n",
    "<ul>\n",
    "    <li>A subsample dictionary which is aimed at representing the structure of our output.</li>\n",
    "    <li>An explanatory and very simplified scheme of the software structure, to present in a very general and divulgatory fashion what the various parts of the code are aimed at.</li>\n",
    "    <li>A Flow diagram of the software (which is also linked to its online pdf version, in order to improve the readability), which is aimed at giving an idea of how the main functions of the code interact.</li>\n",
    "</ul>\n",
    "The final version of the article was then published and is now available <a href=\"http://doi.org/10.5281/zenodo.5070276\">here</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue Closure (06/07/2021) <a class=\"anchor\" id=\"entry_28\"></a> \n",
    "Welcoming the suggestion by our Professor, we commented the final issue with our reply to each of the highlighted points and closed it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
