{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "open-sci-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeK0ebfNr_iH"
      },
      "source": [
        "# 28 - 03 - 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K95Mj7IK-8pe"
      },
      "source": [
        "## First draft of our abstract\n",
        "\n",
        "In our first meeting with the group, we discussed about the topic and created a first draft of our abstract. For this, everyone wrote a draft and we combined our results in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ok0HmEzgPf"
      },
      "source": [
        "# 30 - 03 - 2021\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5WiDrt5_A6G"
      },
      "source": [
        "## Preliminary Analysis: exploring the classes of errors\n",
        "I started to carry some preliminary analysis, in order to butter understand the problem that we need to tackle in our research question. The dataset that we need to use to solve our problem is provided by Silvio Peroni under public license at http://doi.org/10.5281/zenodo.4625300. This dataset contains a two-column CSV file, where the first column (\"Valid_citing_DOI\") contains the DOI of a citing entity retrieved in Crossref, while the second column (\"Invalid_cited_DOI\") contains the invalid DOI of a cited entity identified by looking at the field \"reference\" in the JSON document returned by querying the [Crossref API](https://www.crossref.org/education/retrieve-metadata/rest-api/) with the citing DOI. <br />\n",
        "Among the column containing invalid cited DOIs I noticed some first general classes of errors that invalid the identifier:<br />\n",
        "* **DOIs containing additional URLs:**\n",
        "  1. 10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086 → 10.1016/j.aca.2006.07.086\n",
        "  2. “10.1186/1735-2746-10-21,http://www.ijehse.com/content/10/1/21\" → 10.1186/1735-2746-10-21\n",
        "* **Extra characters at the end:**\n",
        "  1. 10.1061/9780784480502.018] →  10.1061/9780784480502.018\n",
        "  2. 10.1044/1092-4388(2012/11-0316)a →  10.1044/1092-4388(2012/11-0316)\n",
        "* **Extra strings at the end:** \n",
        "  1. 10.1111/j.1099-0860.1997.tb00004.x/abstract> → 10.1111/j.1099-0860.1997.tb00004.x\n",
        "  2. 10.4103/0975-�-7406.163460>accessed8 →  10.4103/0975-7406.163460\n",
        "  3. 10.1007/s10706-019-01181-9(0123456789 → 10.1007/s10706-019-01181-9\n",
        "* **DOIs with wrongly encoded HTML entities:**\n",
        "  1. 10.1379/1466-1268(1997)002lt;0162:tmethi>2.3.co;2 → 10.1379/1466-1268(1997)002<0162:tmethi>2.3.co;2\n",
        "\n",
        "Arcangelo noticed that some **DOIs contain queries to proxy servers or characters forbidden in URLs:**\n",
        "  1. 10.2307/2491102?uid=37380728uid=20uid=40sid=4102564553863 → 10.2307/2491102\n",
        "  2. 10.1016/j.envexpbot.2013.10.018#doilink → 10.1016/j.envexpbot.2013.10.018"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjRJAwpr_Dhc"
      },
      "source": [
        "# 03 - 04 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGrqBwAhsQ9Y"
      },
      "source": [
        "## First draft of Data Management Plan (DMP)\n",
        "In a group meeting, we created a DMP on the platform Argos (https://argos.openaire.eu/) and divided the further work on it (the description of the two datasets) between us.\n",
        "For the DMP, I focused on part **1: Data Summary** and **2: Reusable Data** of the dataset containing the source code used to clean a CSV list of invalid DOI names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BDNcivt_Fsq"
      },
      "source": [
        "# 07 - 04 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpvZM_h43QSZ"
      },
      "source": [
        "\n",
        "## First bites of code: Counting the invalid DOI-to-DOI citations in the CSV\n",
        "\n",
        "I started to carry some preliminary computations on our data, by counting how many pair of invalid DOI-to-DOI citations are in the CSV that we use as input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HGrrK8uvVwz",
        "outputId": "c47167c2-8553-46ec-e98c-385048b7a982"
      },
      "source": [
        "!wget https://zenodo.org/record/4625300/files/invalid_dois.csv\n",
        "\n",
        "# if you are running this notebook locally on Windows 10 use:\n",
        "# pip install wget\n",
        "# !python -m wget https://zenodo.org/record/4625300/files/invalid_dois.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-09 13:11:48--  https://zenodo.org/record/4625300/files/invalid_dois.csv\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64233224 (61M) [text/plain]\n",
            "Saving to: ‘invalid_dois.csv’\n",
            "\n",
            "invalid_dois.csv    100%[===================>]  61.26M  17.2MB/s    in 4.7s    \n",
            "\n",
            "2021-04-09 13:11:54 (12.9 MB/s) - ‘invalid_dois.csv’ saved [64233224/64233224]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuKGIHIg1MLX",
        "outputId": "f506fdab-2840-46b6-de0f-205f98b73621"
      },
      "source": [
        "from csv import reader\n",
        "\n",
        "f = reader(open('invalid_dois.csv'))\n",
        "header = next(f)\n",
        "input_list = [(doi1, doi2) for (doi1, doi2) in f]\n",
        "print(input_list[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('10.14778/1920841.1920954', '10.5555/646836.708343'), ('10.5406/ethnomusicology.59.2.0202', '10.2307/20184517'), ('10.1161/01.cir.63.6.1391', '10.1161/circ.37.4.509'), ('10.1177/1179546820918903', '10.3748/wjg.v10.i5.707.'), ('10.1080/10410236.2020.1731937', '10.1070/10810730903528033'), ('10.1161/strokeaha.112.652065', '10.1161/str.24.7.8322400'), ('10.1177/1049732310393747', '10.1111/j.545-5300.2003.42208.x'), ('10.1155/2017/1491405', '10.3760/cma.j.issn.0366-6999.20131202'), ('10.1161/01.res.68.6.1549', '10.1161/res.35.2.159'), ('10.4018/978-1-5225-2650-6.ch006', '10.1002/per'), ('10.1145/2525314.2594229', '10.5555/1873601.1873616'), ('10.1007/s10619-020-07320-z', '10.3390/sym11070911www.mdpi.com/journal/symmetry'), ('10.1007/s11771-020-4410-2', '10.13745/j.esf.2016.02.011'), ('10.1161/01.cir.102.5.591', '10.1161/circ.85.3.1537115'), ('10.1007/s40617-018-00299-1', '10.1901/jaba.2012.45-657'), ('10.1074/jbc.m508416200', '10.1059/0003-4819-100-4-483'), ('10.1177/2054358119836124', '10.1016/j.amepre.2015.07.017.'), ('10.1002/2014jd022782', '10.1016/j.atmosenv.2008.0305'), ('10.1161/01.cir.97.6.553', '10.1161/circ.66.1.7083497'), ('10.1080/13642537.2013.849275', '10.1080/1364253032000157166'), ('10.1161/01.str.0000057812.51734.ff', '10.1161/str.23.11.1440702'), ('10.1007/978-3-319-78030-6_47', '10.1186/s12933-015-0183-6.'), ('10.1177/1754073918765660', '10.1037/0021–9010.93.3.602'), ('10.1177/0312896217726836', '10.1177/0312896216656720.'), ('10.1145/3313276.3316328', '10.5555/2133036.2133123'), ('10.1145/2834050.2834111', '10.5555/2442626.2442634'), ('10.1145/2939918.2939934', '10.5555/1785594.1785635'), ('10.1161/01.hyp.29.6.1278', '10.1161/res.59.2.2874900'), ('10.1007/s10961-016-9510-7', '10.1002/smj'), ('10.1161/circep.110.954636', '10.1161/res.89.12.1216'), ('10.1177/1179069518824125', '10.3390/brainsci7120164.'), ('10.1145/2835776.2835780', '10.5555/944919.944937'), ('10.1145/3190617', '10.1145/2838344.2856460'), ('10.3389/fpsyg.2016.01919', '10.1177/0890117116661982.'), ('10.1161/01.cir.80.2.285', '10.1161/circ.39.1.48'), ('10.1007/s00415-020-09705-7', '10.1101/390815v1'), ('10.1080/15374416.2014.940623', '10.1111/j.1741–3737.2005.00191.x'), ('10.1161/01.str.25.3.663', '10.1161/str.24.2.7678472'), ('10.1177/0959683617721334', '10.1177/0959683616683260.'), ('10.1007/978-4-431-54391-6_7', '10.5475/geologija.2005.011'), ('10.1161/01.atv.19.1.122', '10.1161/circ.91.9.2488'), ('10.1039/c0cc02213f', '10.1016/j.jpowersour.2010.06.096'), ('10.1111/j.1467-9272.2006.00573_2.x', '10.1111/j.0033-0124.1995.458_h.x'), ('10.4018/ijsda.2013070105', '10.1016/0305-0483(80)90061-4]'), ('10.1016/j.enzmictec.2016.04.004', '10.15376/biores.3.3.929-980'), ('10.1007/s12182-019-00423-y', '10.1190/1.18931.4'), ('10.1161/01.str.0000229878.93759.a2', '10.1161/str.28.6.1185'), ('10.2478/s11696-009-0027-5', '10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086'), ('10.1161/01.cir.0000125742.65841.8b', '10.1161/circ.97.12.1114'), ('10.1161/01.str.0000095791.85737.65', '10.1161/str.31.9.2055')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmynn-Js3g09",
        "outputId": "b368b3f4-e46f-443d-971a-0064f3c70db4"
      },
      "source": [
        "print(len(input_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1223296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x72XyvF925P-",
        "outputId": "e71186dd-e1c8-4712-f137-d91ab812caef"
      },
      "source": [
        "invalid_dois = list(zip(*input_list))[1]\n",
        "print(invalid_dois[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('10.5555/646836.708343', '10.2307/20184517', '10.1161/circ.37.4.509', '10.3748/wjg.v10.i5.707.', '10.1070/10810730903528033', '10.1161/str.24.7.8322400', '10.1111/j.545-5300.2003.42208.x', '10.3760/cma.j.issn.0366-6999.20131202', '10.1161/res.35.2.159', '10.1002/per', '10.5555/1873601.1873616', '10.3390/sym11070911www.mdpi.com/journal/symmetry', '10.13745/j.esf.2016.02.011', '10.1161/circ.85.3.1537115', '10.1901/jaba.2012.45-657', '10.1059/0003-4819-100-4-483', '10.1016/j.amepre.2015.07.017.', '10.1016/j.atmosenv.2008.0305', '10.1161/circ.66.1.7083497', '10.1080/1364253032000157166', '10.1161/str.23.11.1440702', '10.1186/s12933-015-0183-6.', '10.1037/0021–9010.93.3.602', '10.1177/0312896216656720.', '10.5555/2133036.2133123', '10.5555/2442626.2442634', '10.5555/1785594.1785635', '10.1161/res.59.2.2874900', '10.1002/smj', '10.1161/res.89.12.1216', '10.3390/brainsci7120164.', '10.5555/944919.944937', '10.1145/2838344.2856460', '10.1177/0890117116661982.', '10.1161/circ.39.1.48', '10.1101/390815v1', '10.1111/j.1741–3737.2005.00191.x', '10.1161/str.24.2.7678472', '10.1177/0959683616683260.', '10.5475/geologija.2005.011', '10.1161/circ.91.9.2488', '10.1016/j.jpowersour.2010.06.096', '10.1111/j.0033-0124.1995.458_h.x', '10.1016/0305-0483(80)90061-4]', '10.15376/biores.3.3.929-980', '10.1190/1.18931.4', '10.1161/str.28.6.1185', '10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086', '10.1161/circ.97.12.1114', '10.1161/str.31.9.2055')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NwIlTuI_LtS"
      },
      "source": [
        "#09 - 04 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ55ZrLx5Tww"
      },
      "source": [
        "## Useful References for literature review\n",
        "\n",
        "Here I will list the useful references that I found in order to carry a literature review:\n",
        "\n",
        "1. Xu, S., Hao, L., An, X. et al. Types of DOI errors of cited references in Web of Science with a cleaning method. Scientometrics 120, 1427–1437 (2019). https://doi.org/10.1007/s11192-019-03162-4\n",
        "2. Zhu, J., Hu, G. & Liu, W. DOI errors and possible solutions for Web of Science. Scientometrics 118, 709–718 (2019). https://doi.org/10.1007/s11192-018-2980-7 \n",
        "3. Franceschini, F., Maisano, D., & Mastrogiacomo, L. (2015). Errors in DOI indexing by bibliometric databases. Scientometrics, 102(3), 2181–2186. https://doi.org/10.1007/s11192-014-1503-4.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5dknkce0pz"
      },
      "source": [
        "# 10 - 04 - 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ERAbSMP-3qx"
      },
      "source": [
        "## Notes on: Xu, S., Hao, L., An, X. et al. (2019). Types of DOI errors of cited references in Web of Science with a cleaning method. \n",
        "(article: https://doi.org/10.1007/s11192-019-03162-4)<br/>\n",
        "This paper address the problem of DOIs errors in cited references contained in the Web of Science (WoS) database. The authors of this paper collected a set of bibliographic references in the gene editing field and deeply analysed them in order to understand which classes of errors were present in cited DOIs and which possible solution could have been attempted in order to automatically correct them. <br/>\n",
        "After their analysis they found that **many cited DOIs were duplicates** and they **contained various errors** which they generalized in three classes: \n",
        "  1.\tprefix-type errors: DOIs starting with extra characters, e.g. “http://dx.doi.org/10.XXXX/XXXXXXXXXX”\n",
        "  2.\tsuffix-type errors: DOIs containing extra characters at the end, e.g. “10.XXXX/XXXXXXXXXX(EPUB)”\n",
        "  3.\tother types of errors: double underscores, white spaces, forward slashes and XML tags<br />\n",
        "\n",
        "After this generalization, they proposed an algorithmic solution to automatically clean duplicate DOIs and join them. This solution consists of 4 steps: (1) cleaning of prefix-type errors, (2) cleaning of suffix-type errors, (3) removal of incompatible characters and other errors and finally (4) joining of compatible DOIs. The first two steps were carried by using **regular expressions**.<br/>\n",
        "The authors state that the **vast majority of DOI errors belonged to the first category** of prefix-type (92.39%). After applying their algorithm, the authors achieved to reduce drastically the quantity of cited reference containing two and three DOI names from 9,704 to 1,990 and from 45 to 33, respectively. However, the authors acknowledge that their solution was not able to deal with the following issues: (a) to correct similar characters confused with each other, such as “O” versus “0”, “b” versus “6” etc., (b) to distinguish the correct DOI name from multiple DOI names assigned to the same cited reference; (c) to identify DOIs that cannot be resolved by the DOI system; and (d) to identify DOIs that are resolvable, but point to some knowledge unit which is related to the Digital Object but it’s different from it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMk0AZmQ-hrU"
      },
      "source": [
        "## Notes on: Franceschini, F., Maisano, D., & Mastrogiacomo, L. (2015). Errors in DOI indexing by bibliometric databases.\n",
        "(article: https://doi.org/10.1007/s11192-014-1503-4)<br/>\n",
        "In this paper, Franceschini F., Maisano D. & Mastrogiacomo L. provided a taxonomy of errors for two bibliometric databases: Scopus and Web of Science (WoS). What they found out is that errors in these databases fall within two general categories: (1) **author made errors**, due to lack of care of the author when providing the list of cited articles, and (2) **database mapping errors**, due to poor communication between database administrator and data provider. Moreover, they found out (a) that citations obtained from certain publishers are more likely to be omitted than those from other ones, and (b) that same DOIs are often mistakenly attached to multiple publications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q690fvp3AylW"
      },
      "source": [
        "## Notes on: Zhu, J., Hu, G. & Liu, W. (2019). DOI errors and possible solutions for Web of Science.\n",
        "(article: https://doi.org/10.1007/s11192-018-2980-7)<br/>\n",
        "In this paper Zhu, J., Hu, G. & Liu, W. start with the hypothesis that some DOIs assigned to the papers indexed in Web of Science (WoS) are wrongly mapped in the database due to similar characters mistyping: e.g., confusing the number \"0\" with the letter \"O\". In order to carry their research, they queried the WoS database with special strings were the letter \"O\" appeared between two 0-9 numbers (e.g. \"0O1\"). Among the 310 records returned by the system, 119 DOIs were impossible to be resolved within the DOI system. In addition, they found out that many DOIs were invalid due to other type of character mistyping (e.g. \"b\" versus \"6\" and \"Q\" versus \"O\") and that one article had 2 DOIs attached when only one was correct. However, despite these discoveries, the paper only suggests possible solutions for WoS and does not describe any concrete process to carry and evaluate data cleaning processes on incorrect DOIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZSHIXdVV9Uo"
      },
      "source": [
        "# 19 -04 - 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpbgkZ1NWDFb"
      },
      "source": [
        "## Classes of errors: suffix-type errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV9z5f7hWHd_"
      },
      "source": [
        "After a manual revision, I find this recurrent suffix errors:\n",
        "\n",
        "\n",
        "\n",
        "1.   /doi/+\"www.website.com/etc/etc\"\n",
        "2.   /doi/+\"http://dx.doi.org/etc.\"\n",
        "3.   /doi/+\"...........-.-.403420(2001)\"\n",
        "4.   /doi/+\",pp.2206-2222\"\n",
        "5.   /doi/+\",http://etc.\"\n",
        "6.   /doi/ + \".\"\n",
        "7.   /doi/ + \",\"\n",
        "8.  /doi/ + \">accessed8\"\n",
        "9.  /doi/ + \">\"\n",
        "10.  /doi/ + \"/suppinfo\"\n",
        "11.  /doi/ + \"...........32,63(2006)\"\n",
        "12.  \"10.1007/s11199-012-0130-x\" + \",1-16\"\n",
        "13.  \"10.1088/2053-1583/3/4/045006\" + \"/meta\"\n",
        "14.  \"10.1111/j.0735-2751.2004.00237.x\" +\"/abstract\"\n",
        "15.  \"10.1002/smi.1053\"+ \").\"\n",
        "16.  \"10.1038/208365a0\" + \".......208365(1965)\"\n",
        "17.  \"10.1016/j.expneurol.2009.06.012\" + \"uncitedrefs\"\n",
        "18.  \"10.3389/fnins.2016.00584\" + \".5186786.pmid28082858.author\"\n",
        "19.  \"10.1111/j.1365-2486.1999.00252.x\" + \"/full\"\n",
        "20.  \"10.1111/j.1467-9671.2009.01180.x\" + \"/pdf\"\n",
        "21.  \"/doi/\" + \",/doi/\"\n",
        "22. \"10.1101/gr.229202\" + \"articlepublishedonlinebeforemarch2002\"\n",
        "23. \"10.1177/2043820617738836\" + \"journals.sagepub.com/home/dhg\" \n",
        "24. \"10.1177/1468794112468475\" + \"qri.sagepub.com\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPRwl2sDba0B"
      },
      "source": [
        "This is a temporary list of regular expressions which might be used for cleaning suffix-type errors.\n",
        "Regular expressions from 1 to 8 are derived from Xu, S., Hao, L., An, X. et al. Types of DOI errors of cited references in Web of Science with a cleaning method. Scientometrics 120, 1427–1437 (2019). https://doi.org/10.1007/s11192-019-03162-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzXy7ZxK04vR"
      },
      "source": [
        "# these are the patterns\n",
        "# to match suffix errors\n",
        "regex1 = \"\\/-\\/DCSUPPLEMENTAL\"\n",
        "regex2 = \"SUPPINF[0|O](\\.)?\"\n",
        "regex3 = \"[\\.|(|,|;]?PMID:\\d+.*?\"\n",
        "regex4 = \"[\\.|(|,|;]?PMCID:PMC\\d+.*?\"\n",
        "regex5 = \"[(|\\[]EPUBAHEADOFPRINT[)\\]]\"\n",
        "regex6 = \"[\\.|(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}\"\n",
        "regex7 = \"[\\.|(|,|;]*HTTP:\\/\\/.*?\"\n",
        "regex8 = \"[\\.\\/](META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)>?\"\n",
        "regex9 = \"([\\/\\.](META|ABSTRACT|FULL|EPDF|PDF|SUMMARY))?[>|)](LAST)?ACCESSED\\d+\"\n",
        "regex10 = \"[\\.|(|,|;]?[A-Z]*\\.?SAGEPUB.*?\"\n",
        "regex11 = \"<[A-Z\\/]+>\"\n",
        "regex12 = \"\\.{5}.*?\"\n",
        "regex13 = \"[\\.|,|<|>|&|(|;]\"\n",
        "regex14 = \"[\\.;,]PP.\\d+-\\d+\"\n",
        "regex15 = \"[\\.|(|,|;]10.\\d{4}\\/.*?\"\n",
        "\n",
        "regex_lst = [regex1, regex2, regex3, regex4, regex5, regex6, regex7, regex8, regex9, regex10, regex11, regex12, regex13, regex14, regex15]\n",
        "\n",
        "# regex from 1 to 7 are from paper\n",
        "# regex from 8 to 15 are added by me\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNn6aLeV87U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d29a45e-a4aa-46c2-9077-b1832d903432"
      },
      "source": [
        "import csv, re, urllib.request\n",
        "\n",
        "url = 'https://zenodo.org/record/4625300/files/invalid_dois.csv'\n",
        "response = urllib.request.urlopen(url)\n",
        "lines = [l.decode('utf-8') for l in response.readlines()]\n",
        "reader = csv.reader(lines)\n",
        "rows_number = 0\n",
        "occurrences = list()\n",
        "for row in reader:\n",
        "    rows_number += 1\n",
        "    pattern = re.search(\"(.*?)(?:\"+ \"|\".join(regex_lst) + \")$\", row[1].upper())\n",
        "    if pattern is not None:\n",
        "        pattern = pattern.group(1)\n",
        "        occurrences.append((row[1], pattern))\n",
        "print(f\"The wrong DOI names are {len(occurrences)} out of {rows_number}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The wrong DOI names are 148264 out of 1223297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztj3hpJsV2KC",
        "outputId": "84130706-e12d-4983-c1f4-fab54cca9fa7"
      },
      "source": [
        "print(occurrences[5:15])\n",
        "\n",
        "## TO DO:\n",
        "## 1. Deal with closing parenthesis at the end\n",
        "## 2. test on DOIs checked for incorrectness to see if results vary\n",
        "## 3. print output csv\n",
        "## 4. simplify regex to decrease computational time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('10.1177/0890117116661982.', '10.1177/0890117116661982'), ('10.1177/0959683616683260.', '10.1177/0959683616683260'), ('10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086', '10.1016/J.ACA.2006.07.086'), ('10.1007/s10548-017-0554-2.', '10.1007/S10548-017-0554-2'), ('10.1021/bi0100236...........-.-.403420(2001)', '10.1021/BI0100236'), ('10.1016/j.ecoenv.2014.11.015.', '10.1016/J.ECOENV.2014.11.015'), ('10.1016/j.jlumin.2004.10.018.http://dx.doi.org/10.1016/j.jlumin.2004.10.018', '10.1016/J.JLUMIN.2004.10.018'), ('10.3748/wjg.v20.i4.908.', '10.3748/WJG.V20.I4.908'), ('10.1016/j.bone.2013.01.022.', '10.1016/J.BONE.2013.01.022'), ('10.4324/9781315793207.', '10.4324/9781315793207')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6beoMGuUHfnx"
      },
      "source": [
        "## Review  of The Leftovers 2.0 DMP\n",
        "https://doi.org/10.32388/DIA06O "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTG1fYGWHqX1"
      },
      "source": [
        "# 23 - 04 - 2021\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvivppWFFPJ_"
      },
      "source": [
        "##Efficiency of first list of suffix regex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdcGZSceFSP2"
      },
      "source": [
        "Out of the 148264 cited DOIs matched by my regular expression, only 10 were already valid. Out of these 10 DOIs:\n",
        "\n",
        "\n",
        "*   Most of them (7) have been matched due to the fact that they contain queries to proxy servers.\n",
        "*   8 out of 10 cleaned DOIs can still be resolved by the DOI Handle API. However, 1 of them ('10.11591/ijece.v9i4.pp2416-2424' --> '10.11591/IJECE.V9I4') points to a different resource.\n",
        "*  2 cleaned DOIs were no more resolvable by the DOI system:\n",
        "('10.3265/nefrologia.2009.29.5.5157.en.full'--> '10.3265/NEFROLOGIA.2009.29.5.5157.EN' AND '10.7895/ijadr.v0i0.222.' -->'10.7895/IJADR.V0I0.222')\n",
        "\n",
        "I think that this problems can be fixed by checking for DOI validity before cleaning the DOIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwfZaB5q2JS_"
      },
      "source": [
        "# 27 - 04 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDKCLwE_2Okr"
      },
      "source": [
        "## Response letter and third version of the protocol\n",
        "We worked and published a response letter to the peer reviews made by the team Leftovers 2.0 to our protocol and wrote and published a third version of our protocol. \n",
        "This is the revised protocol: https://dx.doi.org/10.17504/protocols.io.bufwntpe\n",
        "This is the response letter to the protocol reviews: https://zenodo.org/record/4724007#.YIhwhX0zb5Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqBNejEjDQkn"
      },
      "source": [
        "# 30 - 04 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAd3ZWDxYgEr"
      },
      "source": [
        "##Suffix regex update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9KnkLBAZNYO"
      },
      "source": [
        "We updated the regular expressions for cleaning suffixes. More specifically:<br/>\n",
        "1. we added an initial slash to the \"suffix_suppinfo\" regex\n",
        "2. We removed the regular expression \"[\\\\.;,]PP.\\d+-\\d+\" because it actually altered a corrected DOI by making it pointing to a different resource (from article to venue)\n",
        "3. We removed the regular expressions for double DOIs \"[\\\\.|\\(|,|;]10.\\d{4}\\/.*?\" because it also matched other symbols inside a DOI\n",
        "4. We added three regular expressions: one for cleaning years at the end of a string, one for cleaning queries to a proxy server and one for clearing fragment specification after the DOI (e.g. \"10.5456/487346#fragment\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMCB_aE5YTzQ",
        "outputId": "e2c9866d-31aa-4bf4-d6b2-be65c244c2ed"
      },
      "source": [
        "suffix_dcsupplemental = \"\\/-\\/DCSUPPLEMENTAL\"\n",
        "suffix_suppinfo = \"\\/SUPPINF[0|O](\\.)?\"\n",
        "suffix_pmid1 = \"[\\.|\\(|,|;]?PMID:\\d+.*?\"\n",
        "suffix_pmid2 = \"[\\.|\\(|,|;]?PMCID:PMC\\d+.*?\"\n",
        "suffix_epub = \"[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]]\"\n",
        "suffix_published_online = \"[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}\"\n",
        "suffix_http = \"[\\.|\\(|,|;]*HTTP:\\/\\/.*?\"\n",
        "suffix_subcontent = \"\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)?\"\n",
        "suffix_accessed = \"[>|\\)](LAST)?ACCESSED\\d+\"\n",
        "suffix_sagepub = \"[\\.|\\(|,|;]?[A-Z]+\\.?SAGEPUB.*?\"\n",
        "suffix_dotted_line = \"\\.{5}.*?\"\n",
        "suffix_delimiters = \"[\\.|,|<|&|\\(|;]+\"\n",
        "suffix_doi_mark = \"\\[DOI\\].*?\"\n",
        "suffix_year = \"\\(\\d{4}\\)?\"\n",
        "suffix_query=\"\\?.*?=.*?\"\n",
        "suffix_hash =\"#.*?\"\n",
        "\n",
        "suffix_regex_lst = [suffix_dcsupplemental, suffix_suppinfo, suffix_pmid1, suffix_pmid2, suffix_epub, suffix_published_online, suffix_http, suffix_subcontent, suffix_accessed, suffix_sagepub, suffix_dotted_line, suffix_delimiters, suffix_doi_mark, suffix_year, suffix_query, suffix_hash]\n",
        "suffix_regex = \"(.*?)(?:\"+ \"|\".join(suffix_regex_lst) + \")$\"\n",
        "print(\"Suffix regex: \", suffix_regex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Suffix regex:  (.*?)(?:\\/-\\/DCSUPPLEMENTAL|\\/SUPPINF[0|O](\\.)?|[\\.|\\(|,|;]?PMID:\\d+.*?|[\\.|\\(|,|;]?PMCID:PMC\\d+.*?|[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]]|[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}|[\\.|\\(|,|;]*HTTP:\\/\\/.*?|\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)?|[>|\\)](LAST)?ACCESSED\\d+|[\\.|\\(|,|;]?[A-Z]+\\.?SAGEPUB.*?|\\.{5}.*?|[\\.|,|<|&|\\(|;]+|\\[DOI\\].*?|\\(\\d{4}\\)?|\\?.*?=.*?|#.*?)$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YGsG3eqErAI"
      },
      "source": [
        "##Checking matches for regex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P0sMfNSa1bY"
      },
      "source": [
        "This is a little script for checking the occurrences of each pattern inside the dataset.<br/>\n",
        "**Note**: this numbers do not represent the actual errors that are corrected by our procedure in the dataset, since a string might be matched by more than one regular expression, even though in our procedure only the one which matches the longest error is used to clean the DOI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGmvfmf1DTPG",
        "outputId": "9ed13309-bea2-4529-f133-9e9c0e964702"
      },
      "source": [
        "import csv, re, urllib.request\n",
        "\n",
        "suffix_dcsupplemental = \"\\/-\\/DCSUPPLEMENTAL\"\n",
        "suffix_suppinfo = \"\\/SUPPINF[0|O](\\.)?\"\n",
        "suffix_pmid1 = \"[\\.|\\(|,|;]?PMID:\\d+.*?\"\n",
        "suffix_pmid2 = \"[\\.|\\(|,|;]?PMCID:PMC\\d+.*?\"\n",
        "suffix_epub = \"[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]]\"\n",
        "suffix_published_online = \"[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}\"\n",
        "suffix_http = \"[\\.|\\(|,|;]*HTTP:\\/\\/.*?\"\n",
        "suffix_subcontent = \"\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)?\"\n",
        "suffix_accessed = \"[>|\\)](LAST)?ACCESSED\\d+\"\n",
        "suffix_sagepub = \"[\\.|\\(|,|;]?[A-Z]+\\.?SAGEPUB.*?\"\n",
        "suffix_dotted_line = \"\\.{5}.*?\"\n",
        "suffix_delimiters = \"[\\.|,|<|&|\\(|;]+\"\n",
        "suffix_doi_mark = \"\\[DOI\\].*?\"\n",
        "suffix_year = \"\\(\\d{4}\\)?\"\n",
        "suffix_query=\"\\?.*?=.*?\"\n",
        "suffix_hash =\"#.*?\"\n",
        "prefix_regex = \"\\.)?(?:HTTP:\\/\\/DX\\.D[0|O]I\\.[0|O]RG\\/|HTTPS:\\/\\/D[0|O]I\\.[0|O]RG\\/)(.*\"\n",
        "markup_regex1 = \"<.*?>.*?</.*?>\"\n",
        "markup_regex2 = \"<.*?/>\"\n",
        "backward_slash_regex = \"\\\\\\\\.*?\"\n",
        "double_dot_regex = \"\\.\\..+\"\n",
        "double_underscore_regex = \"__.+\"\n",
        "\n",
        "regex_lst = [suffix_dcsupplemental, suffix_suppinfo, suffix_pmid1, suffix_pmid2, suffix_epub, suffix_published_online, suffix_http, suffix_subcontent, suffix_accessed, suffix_sagepub, suffix_dotted_line, suffix_delimiters, suffix_doi_mark, suffix_year, suffix_query, suffix_hash, prefix_regex, markup_regex1, markup_regex2, backward_slash_regex, double_dot_regex, double_underscore_regex]\n",
        "\n",
        "url = 'https://zenodo.org/record/4625300/files/invalid_dois.csv'\n",
        "response = urllib.request.urlopen(url)\n",
        "lines = [l.decode('utf-8') for l in response.readlines()]\n",
        "reader = csv.reader(lines)\n",
        "output_dict = dict()\n",
        "for row in reader:\n",
        "    for idx in range(len(regex_lst)):\n",
        "      pattern = re.search(\"(.*?)(?:\"+ regex_lst[idx] + \")$\", row[1].upper())\n",
        "      if pattern is not None:\n",
        "        if str(regex_lst[idx]) not in output_dict.keys():\n",
        "          output_dict[str(regex_lst[idx])] = [row[1]]\n",
        "        else:\n",
        "           output_dict[str(regex_lst[idx])].append(row[1])\n",
        "for key, value in output_dict.items():\n",
        "  print(key, value[:5], len(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\\.|,|<|&|\\(|;]+ ['10.3748/wjg.v10.i5.707.', '10.1016/j.amepre.2015.07.017.', '10.1186/s12933-015-0183-6.', '10.1177/0312896216656720.', '10.3390/brainsci7120164.'] 120828\n",
            "[\\.|\\(|,|;]*HTTP:\\/\\/.*? ['10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086', '10.1016/j.jlumin.2004.10.018.http://dx.doi.org/10.1016/j.jlumin.2004.10.018', '10.1186/1735-2746-10-21,http://www.ijehse.com/content/10/1/21', '10.1016/0014-4894(72)90103-8.http://dx.doi.org/10.1016/0014-4894(72)90103-8', '10.1002/app.23704.http://dx.doi.org/10.1002/app.23704'] 22197\n",
            "\\.)?(?:HTTP:\\/\\/DX\\.D[0|O]I\\.[0|O]RG\\/|HTTPS:\\/\\/D[0|O]I\\.[0|O]RG\\/)(.* ['10.1016/j.aca.2006.07.086.http://dx.doi.org/10.1016/j.aca.2006.07.086', '10.1016/j.jlumin.2004.10.018.http://dx.doi.org/10.1016/j.jlumin.2004.10.018', '10.1016/0014-4894(72)90103-8.http://dx.doi.org/10.1016/0014-4894(72)90103-8', '10.1002/app.23704.http://dx.doi.org/10.1002/app.23704', '10.1006/jcat.2001.3474.http://dx.doi.org/10.1006/jcat.2001.3474'] 22077\n",
            "\\.{5}.*? ['10.1021/bi0100236...........-.-.403420(2001)', '10.1016/j.tibs.2006.12.007...........32,63(2006)', '10.1038/208365a0.......208365(1965)', '10.1021/cm980610m........11,23(1999)', \"10.1021/cr030027b......'...104,3893(2004)\"] 565\n",
            "\\(\\d{4}\\)? ['10.1021/bi0100236...........-.-.403420(2001)', '10.1021/bi3013565(2012)', '10.1016/j.tibs.2006.12.007...........32,63(2006)', '10.1038/208365a0.......208365(1965)', '10.1175/1520-0493(2002)'] 1652\n",
            "\\.\\..+ ['10.1021/bi0100236...........-.-.403420(2001)', '10.11949/j..0438-1157.20180731', '10..annurev.pp.29.060178.002021', '10.1016/j.tibs.2006.12.007...........32,63(2006)', '10.1038/208365a0.......208365(1965)'] 1355\n",
            "[>|\\)](LAST)?ACCESSED\\d+ ['10.4103/0975-�-7406.163460>accessed8', '10.1111/soru.12128/abstract>accessed6', '10.1787/9789264252615-en>accessed4', '10.18356/c5d6a03e-en>accessed31', '10.1111/j.1536-7150.2006.00482.x/full>accessed4'] 65\n",
            "\\\\.*? ['10.1007/978-3-662-49381-6\\\\_56', '10.1007/978-3-662-53008-5\\\\_5', '10.1007/978-94-017-0849-4\\\\_6', '10.1007/978-3-642-02008-7\\\\_13', '10.1007/11603412\\\\_5'] 1030\n",
            "\\/(META|ABSTRACT|FULL|EPDF|PDF|SUMMARY)([>|\\)](LAST)?ACCESSED\\d+)? ['10.1002/3527601953.ch8/summary', '10.1088/2053-1583/3/4/045006/meta', '10.1111/j.0735-2751.2004.00237.x/abstract', '10.1002/spe.995/full', '10.3389/fpubh.2014.00251/abstract'] 2929\n",
            "#.*? ['10.1002/(sici)1099-1263(199611)16:6[amp]lt;509::aid-jat382[#62]3.0.co;2-v', '10.1016/j.envexpbot.2013.10.018#doilink', '10.1111/j.1708-8305.2008.00203.x#_blank', '10.1080/13600800305737#_blank', '10.1007/3-540-35074-8_16#page-1'] 538\n",
            "[\\.|\\(|,|;]?PMID:\\d+.*? ['10.1371/journal.pone.0195878.pmid:29702697', '10.1371/journal.pone.0112567.pmid:25405489', '10.1126/science.1159314pmid:18599777', '10.1371/journal.pone.0035968.pmid:22567121', '10.1371/journal.pone.0136487pmid:2633221'] 81\n",
            "\\?.*?=.*? ['10.2307/40287787?ref=search-gateway:9b0a51cffa50066cd191fecfae1efd61', '10.1007/s40615-018-0491-0?error=cookies_not_supported&code=de5df31c-4792-4aca-9127-7577a8c5060d', '10.1063/1.1148310?crawler=true', '10.2307/2491102?uid=37380728uid=20uid=40sid=4102564553863', '10.2307/2346101?refreqid=search-gateway:025a1890f1052cf99b3585fdaa4b55fd'] 228\n",
            "[\\.|\\(|,|;]?[A-Z]+\\.?SAGEPUB.*? ['10.1177/1066480716628622tfj.sagepub.com', '10.1177/0004865814524218anj.sagepub.com', '10.1177/2043820617738836journals.sagepub.com/home/dhg', '10.1177/2396941516688399journals.sagepub.com/home/dli', '10.1177/2047487317702044journals.sagepub.com/home/ejpc'] 65\n",
            "<.*?/> ['10.1186/1471-2407-13-87<br/>', '10.1093/acprof:osobl/9780195387711.001.0001<br/>', '10.1002/ccd.20643<br/>', '10.4236/ib.2016.81001<br/>', '10.1039/c3nr05496a<br/>'] 28\n",
            "\\[DOI\\].*? ['10.3201/eid0101.950102[doi]', '10.1073/pnas.1104391108[doi]', '10.1111/nyas.12362[doi]', '10.1155/2011/154672[doi]', '10.1152/jn.91268.2008[doi]'] 94\n",
            "\\/-\\/DCSUPPLEMENTAL ['10.1073/pnas.1007524107/-/dcsupplemental', '10.1073/pnas.1319051111/-/dcsupplemental', '10.1073/pnas.1313768111/-/dcsupplemental', '10.1073/pnas.1324140111/-/dcsupplemental', '10.1073/pnas.1324140111/-/dcsupplemental'] 13\n",
            "\\/SUPPINF[0|O](\\.)? ['10.1002/hep.29056/suppinfo', '10.1890/15-0075.1/suppinfo', '10.1890/14.2429.1/suppinfo', '10.1002/ecm.1219/suppinfo', '10.1002/hep.28882/suppinfo'] 49\n",
            "__.+ ['10.1007/978-3-319-04765-2__2', '10.1007/978-3-642-54593-1__4', '10.1007/978-3-642-37222-3__26', '10.1007/978-3-642-37222-3__71', '10.1007/978-3-319-09171-6__3'] 38\n",
            "[\\.|\\(|,|;]?ARTICLEPUBLISHEDONLINE.*?\\d{4} ['10.1101/gr.229202.articlepublishedonlinebeforemarch2002', '10.1101/gr.229202.articlepublishedonlinebeforemarch2002', '10.1101/gr.229102.articlepublishedonlinebeforeprintinmay2002', '10.1101/gr.229202.articlepublishedonlinebeforemarch2002', '10.1101/gr.229102.articlepublishedonlinebeforeprintinmay2002'] 8\n",
            "[\\(|\\[]EPUBAHEADOFPRINT[\\)\\]] ['10.1111/1753-0407.12297[epubaheadofprint]', '10.1016/j.jprot.2014.03.043(epubaheadofprint)', '10.1111/dme.13431(epubaheadofprint)', '10.1021/pr500421v(epubaheadofprint)', '10.1016/j.mito.2014.04.03[epubaheadofprint]'] 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3nKbPrPZLIl"
      },
      "source": [
        "#9 - 05 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glEGmvnhf09K"
      },
      "source": [
        "##Reusing regular expressions from (Xu et al., 2019) in our procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4CUO5Tyf_zJ"
      },
      "source": [
        "In order to understand the novelty and efficiency of our approach we decided to reuse the regular expressions from the work of (Xu et al., 2019) in our procedure instead of our list of regular expressions.<br/>\n",
        "This procedure, as the one used in our paper, makes use of the methods of the class **Support**. For further informations see our [github repository](https://github.com/open-sci/2020-2021-grasshoppers-code) or our [protocol](https://dx.doi.org/10.17504/protocols.io.bunnnvde).<br/>\n",
        "**Note:** before comparing the results of our procedure with those obtained by using the regular expressions from (Xu et al., 2019) we will consider as cleaned DOIs only those which are *both* clean and valid. So we will not compare their results with DOIs which were temporarily invalid or DOIs which were cleaned but not valid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osDm9deEZKFx"
      },
      "source": [
        "from support import Support\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "doi_logs = dict()\n",
        "\n",
        "def clean_doi(doi):\n",
        "    prefix_regex = \"^(?:D[0|O]I\\/?|HTTP:\\/\\/DX\\.D[0|O]I\\.[0|O]RG\\/|[0|O]RG\\/|[:\\/]|\\d+\\.HTTP:\\/\\/DX\\.D[0|O]I\\.[0|O]RG\\/?)+(.*)\"\n",
        "    suffix_regex = \"(.*?)(?:\\/-\\/DCSUPPLEMENTAL|\\/SUPPINF[0|O]\\.?|[\\s\\.;]?PMID:[\\d]+|[\\.\\/:]|[\\s\\.;]?PMCID:PMC\\d+|[\\(\\.;]EPUB|[\\(\\[]EPUBAHEADOFPRINT[\\)\\]]|[\\s\\.;]?ARTICLEPUBLISHEDONLINE.*?\\d{4}|[\\.\\(]*HTTP:\\/\\/.*?)$\"\n",
        "    tmp_doi = doi.replace(\" \", \"\")\n",
        "    prefix_match = re.search(prefix_regex, tmp_doi, re.IGNORECASE)\n",
        "    classes_of_errors = {\n",
        "        \"prefix\": 0,\n",
        "        \"suffix\": 0,\n",
        "        \"other-type\": 0\n",
        "    }\n",
        "    if prefix_match:\n",
        "        tmp_doi = prefix_match.group(1)\n",
        "        classes_of_errors[\"prefix\"] += 1\n",
        "    suffix_match = re.search(suffix_regex, tmp_doi, re.IGNORECASE)\n",
        "    if suffix_match:\n",
        "        tmp_doi = suffix_match.group(1)\n",
        "        classes_of_errors[\"suffix\"] += 1\n",
        "    new_doi = re.sub(\"\\\\\\\\\", \"\", tmp_doi)\n",
        "    new_doi = re.sub(\"__\", \"_\", new_doi)\n",
        "    new_doi = re.sub(\"\\\\.\\\\.\", \".\", new_doi)\n",
        "    new_doi = re.sub(\"<.*?>.*?</.*?>\", \"\", new_doi)\n",
        "    new_doi = re.sub(\"<.*?/>\", \"\", new_doi)\n",
        "    if new_doi != tmp_doi:\n",
        "        classes_of_errors[\"other-type\"] += 1\n",
        "    return new_doi, classes_of_errors\n",
        "\n",
        "\n",
        "def procedure(data):\n",
        "    output = list()\n",
        "    pbar = tqdm(total=len(data))\n",
        "    for row in data:\n",
        "        invalid_cited_doi = row[\"Invalid_cited_DOI\"]\n",
        "        unclean_dictionary = {\n",
        "            \"Invalid_cited_DOI\": invalid_cited_doi,\n",
        "            \"Valid_DOI\": \"\",\n",
        "            \"Prefix_error\": 0,\n",
        "            \"Suffix_error\": 0,\n",
        "            \"Other-type_error\": 0\n",
        "        }\n",
        "        new_doi, classes_of_errors = clean_doi(invalid_cited_doi)\n",
        "        clean_dictionary = {\n",
        "            \"Invalid_cited_DOI\": invalid_cited_doi,\n",
        "            \"Valid_DOI\": new_doi,\n",
        "            \"Prefix_error\": classes_of_errors[\"prefix\"],\n",
        "            \"Suffix_error\": classes_of_errors[\"suffix\"],\n",
        "            \"Other-type_error\": classes_of_errors[\"other-type\"]\n",
        "        }\n",
        "        if new_doi != invalid_cited_doi and new_doi != \"\":\n",
        "            handle = Support().handle_request(url=f\"https://doi.org/api/handles/{new_doi}\", cache_path=\"\",\n",
        "                                              error_log_dict=doi_logs)\n",
        "            if handle is not None:\n",
        "                if handle[\"responseCode\"] == 1:\n",
        "                    output.append(clean_dictionary)\n",
        "                else:\n",
        "                    output.append(unclean_dictionary)\n",
        "            else:\n",
        "                output.append(unclean_dictionary)\n",
        "        else:\n",
        "            output.append(unclean_dictionary)\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    return output\n",
        "\n",
        "## our procedure stores only cleaned DOIs which are then\n",
        "## validated through the DOI handle API\n",
        "data = Support.process_csv_input(path=\"invalid_dois.csv\")\n",
        "output = procedure(data)\n",
        "\n",
        "Support().dump_csv(data=output, path=\"./output.csv\")\n",
        "\n",
        "number_of_valids = 0\n",
        "for row in output:\n",
        "    if row[\"Valid_DOI\"] != \"\":\n",
        "        number_of_valids += 1\n",
        "print(number_of_valids)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ebw6ZmJk21V"
      },
      "source": [
        "#11 - 05 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTkldbB6k5Ll"
      },
      "source": [
        "##Bug fixing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Euoxkvk9n4"
      },
      "source": [
        "We noticed that in our procedure there was a bug: specifically, the software mistakenly considered all DOIs as processed by our regular expressions even if no error match were found. This caused our procedure to be considerably slower since it double checked each DOI through the DOI API even if it was declared as valid in the first check.\n",
        "For seeing our corrections see this github [commit](https://github.com/open-sci/2020-2021-grasshoppers-code/commit/15c1702af6aa0b9d49a878a9f9133a5ed837c144#diff-bbf813a3906ac45225eea030e88e040f076f0e3cc7ff2033d86bd2cebebf3744)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBAH4I5KidI3"
      },
      "source": [
        "# 17 - 05 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCfH9NQtiktu"
      },
      "source": [
        "##Updated protocol\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM34V2liirxM"
      },
      "source": [
        "We updated our protocol according to the issues presented by prof. Peroni on this [github issue](https://github.com/open-sci/2020-2021/issues/30).<br/>\n",
        "The different changes to the protocols, with the respective problems which they address, are listed in the [last_issue.md](https://github.com/open-sci/2020-2021-grasshoppers-code/blob/main/last_issue.md) file in our Github repo, under the section \"Protocol\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWFxOpe-j-uE"
      },
      "source": [
        "#19 - 05 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYSu--aAm6YZ"
      },
      "source": [
        "##Updated README.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQylrNChkHL-"
      },
      "source": [
        "We updated the [README.md](https://github.com/open-sci/2020-2021-grasshoppers-code/blob/main/README.md) file in our github repository with information on how to reproduce the experiments, hardware and setup required and linked resources (e.g. website, protocol, data management plan, paper and presentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6QM6WekkNN_"
      },
      "source": [
        "# 22 - 05 - 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVbd3DzpkSSH"
      },
      "source": [
        "## Manual check of 100 random DOIs\n",
        "We manually check 100 randomly sampled valid DOIs obtained from our cleaning procedure in order to estimate how many of them were actually present in the reference list of the citing article. 98 out of 100 resulted as presented. <br/>\n",
        "For one DOI it was not possible to verify if it was actually in the reference list of the citing article since the citing article was behind paywall. Another DOI (\"10.1007/s10479-011-0841-3\") was not present in the reference list of the citing article, however neither its uncleaned form was (\"10.1007/s10479-011-0841-3.\"), although it was reported by Crossref. This mismatch can be explained as a processing error made by the platform that published the article, that is bioRxiv, since the same invalid DOI appears 118 times in the dataset analyzed and not even one in the articles that mention it."
      ]
    }
  ]
}