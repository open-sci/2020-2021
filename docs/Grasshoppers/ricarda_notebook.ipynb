{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28.3.2021 ##\n",
    "### First draft of abstract ###\n",
    "In our first meeting with the group, we discussed about the topic and created a first draft of our abstract.\n",
    "For this, everyone wrote a draft and we combined our results in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29.3.2021 ##\n",
    "### Revision of abstract ###\n",
    "In order to comply with the structure shown in https://www.emerald.com/insight/content/doi/10.1108/JD-02-2020-0030/full/html, I revised and restructured our abstract and uploaded the new version the next day, after the other group members agreed with the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2021 ##\n",
    "### First draft of Data Management Plan (DMP) ###\n",
    "In a group meeting, we created a DMP on the platform Argos (https://argos.openaire.eu/) and divided the further work on it (the description of the two datasets) between us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2021 ##\n",
    "### Adding small parts to DMP ###\n",
    "I concentrated on the parts 6 and 7 of the datasets. When we were all done with our part of the work, we created the first version of our DMP: https://doi.org/10.5281/zenodo.4663016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2021 ##\n",
    "### Revising first version of DMP ###\n",
    "Reading the first version of our DMP, I noticed some issues that we revised and updated, creating this version: https://doi.org/10.5281/zenodo.4665853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4.2021 ##\n",
    "### Literature review ###\n",
    "Based on a Google Scholar search with the keywords \"wrong doi\" \"invalid doi\" and \"doi error\", I started with the literature review for the project. I continued the search following the cited references that seemed to contain information about error classes occuring in DOI names and (automatic) methods for fixing and cleaning the DOIs. Especially Xu, S., Hao, L., An, X. et al. Types of DOI errors of cited references in Web of Science with a cleaning method. Scientometrics 120, 1427â€“1437 (2019). https://doi.org/10.1007/s11192-019-03162-4 (which we already found before) seems to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.04.2021 ##\n",
    "### First draft of workflow in group ###\n",
    "Based on the literature review, we created a workflow very similar to the one described by Xu et al. using https://www.protocols.io/ .\\\n",
    "Classes of errors: prefix-type, suffix-type and other-type errors\\\n",
    "Main method used to clean errors: regular expressions\\\n",
    "Input: CSV file https://zenodo.org/record/4625300/files/invalid_dois.csv\\\n",
    "Output: CSV file: cited DOI, modified DOI, type of error\\\n",
    "Before and after procedure: check validity of DOI making use of the DOI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.04.2021 ##\n",
    "### Trying to implement DOI check ###\n",
    "Code to check one DOI by replacing handle var:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responseCode': 1, 'handle': '10.1016/j.eswa.2007.09.055', 'values': [{'index': 1, 'type': 'URL', 'data': {'format': 'string', 'value': 'https://linkinghub.elsevier.com/retrieve/pii/S0957417407004629'}, 'ttl': 86400, 'timestamp': '2019-01-03T12:20:32Z'}, {'index': 700050, 'type': '700050', 'data': {'format': 'string', 'value': '20111118023200000'}, 'ttl': 86400, 'timestamp': '2019-01-03T12:20:32Z'}, {'index': 100, 'type': 'HS_ADMIN', 'data': {'format': 'admin', 'value': {'handle': '0.na/10.1016', 'index': 200, 'permissions': '111111110010'}}, 'ttl': 86400, 'timestamp': '2019-01-03T12:20:32Z'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests as req\n",
    "handle = \"10.1016/j.eswa.2007.09.055\"\n",
    "r = req.get(\"https://doi.org/api/handles/\" + handle)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used for first attempt to check whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import csv\n",
    "\n",
    "with open(\"invalid_dois.csv\", encoding='Latin1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    with open(\"doi_check.csv\", \"w\", newline='', encoding='Latin1') as result:\n",
    "        csv_writer = csv.writer(result, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(['DOI', 'ResponseCode'])\n",
    "        for row in csv_reader:\n",
    "            if row[0] != \"Valid_citing_DOI\":\n",
    "                r = req.get(\"https://doi.org/api/handles/\" + row[1])\n",
    "                rjson = r.json()\n",
    "                csv_writer.writerow([rjson[\"handle\"], str(rjson[\"responseCode\"])])\n",
    "                if rjson[\"responseCode\"] != 100:\n",
    "                    print(rjson[\"handle\"] + \",Code \" + str(rjson[\"responseCode\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223297\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"invalid_dois.csv\", encoding='Latin1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    print(len(list(csv_reader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to check the results, the code ran for about one hour before stopping with a connection error. In this time, 5707 results were created. Like this, for the whole dataset, we would need 214 hours to compute, which is quite unrealistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.04.2021 ##\n",
    "### Trying to improve code, investigating output from first attempt ###\n",
    "Proposed code for future attempts, leaving out all valid DOIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import csv\n",
    "\n",
    "with open(\"invalid_dois.csv\", encoding='Latin1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    with open(\"only_invalid.csv\", \"w\", newline='', encoding='Latin1') as result:\n",
    "        csv_writer = csv.writer(result, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(['DOI', 'ResponseCode'])\n",
    "        for row in csv_reader:\n",
    "            if row[0] != \"Valid_citing_DOI\":\n",
    "                r = req.get(\"https://doi.org/api/handles/\" + row[1])\n",
    "                rjson = r.json()\n",
    "                if rjson[\"responseCode\"] != 1:\n",
    "                    csv_writer.writerow([rjson[\"handle\"], str(rjson[\"responseCode\"])])\n",
    "                if rjson[\"responseCode\"] != 100:\n",
    "                    print(rjson[\"handle\"] + \",Code \" + str(rjson[\"responseCode\"]))\n",
    "\n",
    "#TODO: add possibility to restart where we left after crash?\n",
    "#TODO: correct output format (leave out valid dois? more columns?)\n",
    "#TODO: how make it possible to compute all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating on the result list from 16.4.2021, I found out about some errors and solutions:\n",
    "\n",
    "Erroneous comma in DOI:\n",
    "- Replace comma with dot, e.g. 10.1016/j.eswa,2007.09.055 --> 10.1016/j.eswa.2007.09.055\n",
    "- Leave out comma, e.g. 10.1038/s,41598-017-04125-6 --> 10.1038/s41598-017-04125-6\n",
    "\n",
    "Erroneous strings added to end of DOI:\n",
    "- Leave out part after comma, e.g. 10.1002/asi.22647,pp.2206-2222 --> 10.1002/asi.22647\n",
    "- Leave out part after many dots, e.g. 10.1021/cm980610m........11,23(1999) --> 10.1021/cm980610m\n",
    "- Leave out whitespaces (after comma?), e.g. after doi: 10.1016/j.bar.2014.06.001\n",
    "- Leave out dot at end of doi, e.g. 10.1038/bdjopen.2017.10. --> 10.1038/bdjopen.2017.10\n",
    "- Leave out \"/pdf\" at end: e.g. 10.1088/1755-1315/95/5/052007/pdf --> 10.1088/1755-1315/95/5/052007\n",
    "\n",
    "Others:\n",
    "- Missing suffix, e.g. 10.1016/\n",
    "- 301 response: prefix error? e.g. for doi: 10.16/j.amjsurg.2005.10.023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
